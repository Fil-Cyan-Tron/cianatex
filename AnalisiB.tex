\documentclass{article}

\usepackage[depression]{cianatex}

\title{Formulario pazzo sperindio per Delladio}
\author{Filippo $\L$. Troncana}
\date{A.A. 2023/2024}

\begin{document}

\maketitle

\section{Integrali}

\subsection{Integrale di Riemann}

\begin{proposition}{Teorema fondamentale del calcolo integrale}{TFC}
    Sia $G:[a,b]\to \R$ tale che $g = G'$. Vale
    \[\int_a^b g(x) \de x = G(b)-G(a) =: [G(x)]_a^b\]    
\end{proposition}

\begin{proposition}{Formula dell'integrale per parti}{FIPP}
    Siano $f,g : [a,b]\to\R$ due funzioni $\mc{R}([a,b])$ tali che $g = G'$ e $f = F'$. Vale
    \[\int_a^b F(x)g(x) \de x +  \int_a^b  f(x) G(x) \de x = [F(x)G(x)]_a^b \]
\end{proposition}

\begin{proposition}{Integrale per sostituzione}{IFC}
    Sia $x = g(t)$ con $g : [a,b]\to\R$ tale che $g$ sia continua e derivabile e sia $f : [g(a),g(b)]\to \R$ integrabile. Vale:
    \[\int_{g(a)}^{g(b)} f(x) \de x = \int_a^b f(g(t)) \cdot g'(t) \de t \]
\end{proposition}

\subsection{Integrali $\R^3 \to \R$}

\begin{proposition}{Compatibilità Riemann-Lebesgue}{}
    Sia $f: [a,b]\to\R$ una funzione $\mc{R}([a,b])$. Valgono i seguenti fatti:\begin{enumerate}
        \item $f$ è $\L^1$-sommabile su $[a,b]$.
        \item $f$ è $\mc{C}^0(x)$ a meno di un numero finito di $x \in [a,b]$
        \item Vale l'uguaglianza \[\int_{[a,b]} f \de\L^1 = \int_a^b f(x)\de x\]
    \end{enumerate}
\end{proposition}

\begin{theorem}{Teorema di Fubini rigoroso}{Fubinitrue}
    Siano $X, Y \in \ob(\setcat)$, siano  $\mu : 2^X \to [0,+\infty]$ e $\nu : 2^Y \to [0,+\infty]$ due misure esterne $\sigma$-finite e sia $f : X\times Y \to [-\infty,+\infty]$ una funzione $\mu \times \nu$-misurabile su tutto $X\times Y$ e $\mu \times \nu$-sommabile su un $S \in \mc{M}_{\mu \times \nu}$.\\
    Valgono i seguenti fatti:\begin{enumerate}
        \item $S_x = \left\{ y \in Y | (x,y) \in S \right\}$ è $\nu$-misurabile $\forall_\mu x \in X$.
        \item $f|_x : y \mapsto f(x,y)$ è $\nu$-sommabile su $S_x$ per $\forall_\mu x \in X$.
        \item $x\mapsto \int_{S_x}\ f|_x \de\nu$ è $\mu$-sommabile
        \item Vale l'uguaglianza:
        \[\int_S f \de(\mu\times\nu) = \int_X \int_{S_x} f|_x \de\nu \de\mu\] 
    \end{enumerate}
\end{theorem}

\begin{proposition}{Teorema di Fubini \it{avec les mains}}{}
    Sia $E \subset \R^3$ tale che $E = [a,b]\times E_x$ e sia $f : E \to \R$ una funzione $\L^3$-sommabile. Vale l'uguaglianza:
    \[\int_E f \de \L^3 = \int_{[a,b]}\int_{E_x} f \de \L^2(y,z) \de \L^1(x)\] 
\end{proposition}

\begin{definition}{Matrice differenziale e fattore di trasformazione}{Jacobian}
    Sia $\varphi : \R^n \to \R^m$ una funzione derivabile su un aperto $A$ di $\R^n$.\\
    Si dice \bemph{matrice differenziale} (o matrice Jacobiana) di $\varphi$ per $x \in A$ la matrice
    \[D_\varphi(x) := \begin{pmatrix}
        \partial_1 \varphi_1 (x) & \dots & \partial_n \varphi_1 (x)\\
        \vdots & \ddots & \vdots \\
        \partial_1 \varphi_m (x) & \dots & \partial_n \varphi_m (x)
    \end{pmatrix} \quad \text{dove} \quad \partial_i \varphi_j(x) := \frac{\partial \varphi_j}{\partial x_i}(x)\]
    Mentre si dice \bemph{fattore di trasformazione} di $\varphi$ la quantità:
    \[J_\varphi(x) = \sqrt{ \det{ D_\varphi^t (x) \times D_\varphi(x) } }\]
\end{definition}

\begin{definition}{$(n,N)$-parametrizzazione regolare}{regparam}
    Siano $n\le N \in \N$, sia $C$ un compatto di $\R^n$ tale che $C$ sia la chiusura di un aperto $A$ tale che $\L^n(\partial A) = 0$ e sia contenuto in un altro aperto $A'$.\\
    Sia $\varphi : A' \to \R^N$ tale che:\begin{itemize}
        \item $\varphi$ sia iniettiva su $C$.
        \item $\varphi \in \mc{C}^0(C)$.
        \item $\varphi \in \mc{C}^1(A')$.
        \item $J_\varphi(x) \neq 0$ per ogni $x \in A$.
    \end{itemize}
    Allora $\varphi$ si dice \bemph{$(n,N)$-parametrizzazione regolare} della superficie $\varphi(C)$.
\end{definition}

\begin{remark}{Fattori di trasformazione utili}{}
    Sia $\varphi$ una $(n,N)$-parametrizzazione regolare. Valgono i seguenti:\begin{itemize}
        \item Se $n = 1$, ovvero $\varphi$ descrive una curva, vale $J_\varphi(x) = ||\varphi'(x)||$.
        \item Se $n = 2$ e $N = 3$, vale $J_\varphi(x) = ||D_{1,\varphi}(x) \wedge D_{1,\varphi}(x)||$.
        \item Se $n = N$, vale $J_\varphi(x) = |\det{D_\varphi (x)}|$.
    \end{itemize}
\end{remark}

\begin{example}{Coordinate cilindriche (polari)}{}
    \[\text{Sia} \quad \gamma : [0,+\infty[ \times [0,2\pi] \times \R \quad \text{tale che} \quad \gamma (\rho,\phi, z) = \begin{pmatrix}  \rho\cos\phi \\  \rho\sin\phi \\  z \end{pmatrix}= \begin{pmatrix} x \\ y \\ z    \end{pmatrix}\]
    questa è una $(3,3)$-parametrizzazione regolari di $\R^3$ (oppure di $\R^2 \embin \R^3$ fissando $z$) che corrisponde al sistema di coordinate cilindriche (o polari)

    \begin{center}
        \tdplotsetmaincoords{60}{110}
        \begin{tikzpicture}[scale=3, tdplot_main_coords]
            \coordinate (O) at (0,0,0);
            \draw[thick,->] (0,0,0) -- (1,0,0) node[anchor=north east]{$x$};
            \draw[thick,->] (0,0,0) -- (0,1,0) node[anchor=north west]{$y$};
            \draw[thick,->] (0,0,0) -- (0,0,1) node[anchor=south]{$z$};
            \tdplotsetcoord{P}{1}{30}{60}
            \draw plot [mark=*, mark size=0.2] (P) node [right] {\scriptsize$(\rho,\phi,z)$};
            \draw[dashed] (O) -- (P);
            \draw[->, thick, color=black] (O) -- (Pxy) node [below right] {$\rho$};
            \draw[dashed, color=black] (P) -- (Pxy);
            \tdplotdrawarc{(O)}{0.2}{0}{60}{anchor=north}{$\phi$}
            \draw[dashed, color=black] (P) -- (Pz) node [below left] {$z$};
        \end{tikzpicture}        
    \end{center}
	E il suo fattore di trasformazione è $J_\gamma(\rho,\phi,z) = \rho$.
\end{example}

\begin{example}{Coordinate sferiche}{}
    \[\text{Sia} \quad \sigma : [0,+\infty[\times [0, \pi]\times [0,2\pi] \quad \sigma(r, \theta, \phi) = \begin{pmatrix} r\sin\theta\cos\phi \\ r\sin\theta\sin\phi \\ r\cos\theta \end{pmatrix}= \begin{pmatrix} x \\ y \\ z    \end{pmatrix}\]    
    Questa è una $(3,3)$-parametrizzazione regolare di $\R^3$ che corrisponde alle coordinate sferiche
    \begin{center}
        \tdplotsetmaincoords{60}{110}
        \begin{tikzpicture}[scale=3, tdplot_main_coords]
            \coordinate (O) at (0,0,0);
            \draw[thick,->] (0,0,0) -- (1,0,0) node[anchor=north east]{$x$};
            \draw[thick,->] (0,0,0) -- (0,1,0) node[anchor=north west]{$y$};
            \draw[thick,->] (0,0,0) -- (0,0,1) node[anchor=south]{$z$};
            \tdplotsetcoord{P}{1}{30}{60}
            \draw plot [mark=*, mark size=0.2] (P) node [right] {\scriptsize$(r,\theta,\phi)$};
            \draw[->, thick] (O) -- (P) node [midway, below right] {$r$};
            \draw[dashed, color=black] (O) -- (Pxy);
            \draw[dashed, color=black] (P) -- (Pxy);
            \tdplotdrawarc{(O)}{0.2}{0}{60}{anchor=north}{$\phi$}
            \tdplotsetthetaplanecoords{60}
            \tdplotdrawarc[tdplot_rotated_coords]{(0,0,0)}{0.4}{0}%
                {30}{anchor=south}{$\theta$}
        \end{tikzpicture}
    \end{center}
    E il suo fattore di trasformazione è $J_\sigma(r,\theta,\phi) = r^2 \sin\theta$
\end{example}

\begin{theorem}{Teorema della Formula dell'Area}{TFA}
    Sia $C$ un compatto di $\R^n$ e $\varphi : C \to \R^N$ una $(n,N)$-parametrizzazione regolare con fattore di trasformazione $J_\varphi (x)$ e $f : \varphi(C)\to \R$ una funzione $\mc{C}^0(\varphi(C))$. Vale l'uguaglianza:
    \[\int_{\varphi(C)} f \de \H^n = \int_{C} (f\circ \varphi) \cdot J_\varphi \de \L^n\]
\end{theorem}

\begin{remark}{}{}
    Nel caso in cui $\varphi$ sia una $(1,1)$-parametrizzazione regolare, il teorema si riduce all'\href{prop:IFC}{integrale per sostituzione}.
\end{remark}

\subsection{Integrali $\R^3 \to \R^3$}

\begin{remark}{Regolarità a tratti}{}
    Quello che diciamo adesso sulle curve o superfici regolari vale anche su quelle regolari a tratti, basta considerare la famiglia di parametrizzazioni a tratti e sommare, dai che è easy e credo in voi.
\end{remark}

\begin{definition}{Campo vettoriale tangente e normale}{}
    Siano $\gamma : C = \bar{A} \to \R^N$ una $(1,N)$-parametrizzazione regolare della curva $\Gamma$ e $\sigma : D = \bar{B} \to \R^3$ una $(2,3)$-parametrizzazione regolare della superficie $\Sigma$. Allora:\begin{itemize}
        \item Il campo vettoriale $\tau_\Gamma : A \to \mathbb{S}^{N-1}$ definito da $\tau_\Gamma := \hat{\gamma'}$ si dice \bemph{campo vettoriale tangente} a $\Gamma$ ed è invariante (a meno di orientazione) per parametrizzazioni.
        \item Il campo vettoriale $\nu_\Sigma : B \to \mathbb{S}^2$ definito da $\nu_\Sigma := \hat{v_\sigma}$ con $ v_\sigma := D_1 \sigma \wedge D_2 \sigma$ si dice \bemph{campo vettoriale normale} a $\Sigma$ ed è invariante (a meno di orientazione) per parametrizzazioni.
    \end{itemize}
\end{definition}

\begin{definition}{Integrale di un campo vettoriale su una curva o superficie orientata}{}
    Sia $\Gamma \subset \R^n$ l'immagine di una $(1,n)$-parametrizzazione regolare con campo vettoriale tangente $\tau$ e sia $F: \R^n \to \R^n$ un campo vettoriale (non so quali siano le ipotesi di regolarità ma di solito in esame sono carini). Definiamo l'\bemph{integrale del campo sulla curva}:
    \[\int_{(\Gamma,\tau)} F := \int_\Gamma F \cdot \tau \de \H^1\]   
    Analogamente, sia $\Sigma \subset \R^3$ l'immagine di una $(2,3)$-parametrizzazione regolare con campo vettoriale normale $\nu$ e sia $V : \R^3 \to \R^3$ un campo vettoriale. Definiamo l'\bemph{integrale del campo attraverso la superficie}:
    \[\int_{\Sigma,\nu} V := \int_\Sigma V \cdot \nu \de \H^2\]
\end{definition}

\begin{remark}{}{}
    Come nelle definizioni precedenti, valgono queste identità:
    \[\int_{(\Gamma,-\tau)} F = - \int_{(\Gamma,\tau)} F \quad \text{e} \quad \int_{(\Sigma,-\nu)} V = - \int_{(\Sigma,\nu)} V\]
\end{remark}

\begin{definition}{Divergenza di un campo vettoriale}{}
    Sia $F:\R^3 \to \R^3$ un campo vettoriale tale che $F = (F_x, F_y, F_z)$.\\
    Si dice \bemph{divergenza} di $F$ la funzione $\nabla \cdot F : \R^3 \to \R$:
    \[\nabla \cdot F := \frac{\partial F_x}{\partial x} + \frac{\partial F_y}{\partial y} + \frac{\partial F_z}{\partial z}\]
\end{definition}

\begin{theorem}{Teorema di Gauss della divergenza}{}
    Sia $E\subset \R^3$ un insieme tale che $(\partial E, \nu)$ sia una superficie regolare orientata e $F:\R^3 \to \R^3$ un campo vettoriale $\mc{C}^1$. Vale
    \[\int_E \nabla \cdot F \de \L^3 = \int_{(\partial E, \nu)} F = \int_{\partial E} F \cdot \nu \de \H^2 \]
\end{theorem}

\begin{theorem}{Teorema di Gauss-Green nel piano}{}
    Sia $E \subset \R^2$ un insieme tale che $(\partial E, \tau)$ sia una curva regolare orientata e $F : \R^2 \to \R^2$ un campo vettoriale $\mc{C}^1$. Vale
    \[\int_E \nabla \cdot F \de \L^2 = \int_{(\partial E, \tau)} F = \int_{\partial E} F \cdot \tau \de \H^1 = \int_E D_xF_y - D_yF_x \de \L^2\]
\end{theorem}

\begin{definition}{Rotore di un campo vettoriale}{}
    Sia $F:\R^3 \to \R^3$ un campo vettoriale $\mc{C}^1$.\\
    Si definisce \bemph{rotore} di $F$ il campo vettoriale $\nabla \wedge F : \R^3 \to \R^3$ definito come:
    \[\nabla \wedge F := \hat{x}\left(\frac{\partial F_z}{\partial y} - \frac{\partial F_y}{\partial z} \right) + \hat{y}\left( \frac{\partial F_x}{\partial z} - \frac{\partial F_z}{\partial x} \right) + \hat{z}\left(\frac{\partial F_y}{\partial x} - \frac{\partial F_x}{\partial y}\right)\]
\end{definition}

\begin{theorem}{Teorema di Stokes}{}
    Sia $(\Sigma,\nu)$ una superficie regolare orientata tale che $(\partial\Sigma,\tau)$ sia una curva regolare orientata e sia $F:\R^3 \to \R^3$ un campo vettoriale $\mc{C}^1$. Valgono:
    \[\int_{(\Sigma,\nu)} \nabla \wedge F = \int_{(\partial\Sigma,\tau)} F \quad text{e} \quad \int_{(\Sigma,-\nu)} \nabla \wedge F = \int_{(\partial\Sigma,-\tau)} F\]
\end{theorem}

\section{Fourier}

\begin{definition}{Spazio di Banach}{}
    Sia $B$ un $\R$-spazio vettoriale dotato di una norma $||\cdot||$.\\
    Se $B$ è completo rispetto alla metrica $d(x,y) = ||y-x||$, allora $B$ si dice \bemph{spazio di Banach}.
\end{definition}

\begin{definition}{Spazi $L^p$}{}
    Sia $(X,A,\mu)$ uno spazio con misura, $\mathbb{L}(X,A,\mu)$ l'insieme delle funzioni $\mu$-integrabili da $X$ in $\R$ e $p \in [1,+\infty]$. Definiamo la funzione $|||\cdot|||_p : \mathbb{L}\to[0,+\infty]$ come:
    \[|||f|||_p := \left(\int_X |f|^p \de \mu\right)^{1/p} \quad \text{se } p \neq +\infty, \quad \sup_X |f| \quad \text{altrimenti}\]    
    Indichiamo allora con $\L^p(X,A,\mu)$ il sottospazio di $\mathbb{L}(X,a,\mu)$ tali che $|||f|||_p \neq +\infty$ e definiamo la relazione di equivalenza $\sim_\mu$ come $f\sim_\mu g$ se e solo se sono uguali $\mu$-quasi ovunque.\\
    Definiamo $L^p(X,A,\mu) := \L^p(X,A,\mu)/\sim_\mu$ e $||f||_p := ||[f]||_p = |||f|||_p$.
\end{definition}

\begin{remark}{}{}
    $(L^p(X,A,\mu),||\cdot||_p)$ è uno spazio vettoriale normato.
\end{remark}

\begin{theorem}{Teorema di Fisher-Riesz}{}
    Sia $(X,A,\mu)$ uno spazio con misura.\\
     $(L^p(X,A,\mu), ||\cdot||_p)$ è uno spazio di Banach.
\end{theorem}

\begin{definition}{Spazio di Hilbert}{}
    Sia $H$ un $\R$-spazio vettoriale dotato di un prodotto scalare $\cdot$. Se $H$ è di Banach rispetto alla norma indotta dal prodotto scalare, ovvero $||v|| := \sqrt{v\cdot v}$, allora $H$ si dice \bemph{spazio di Hilbert}.
\end{definition}

\begin{proposition}{}{}
    $(L^2(X,A,\mu), \cdot)$ col prodotto scalare definito come:
    \[[f] \cdot [g] := \int_X f g \de \mu\]
    È uno spazio di Hilbert ed è l'unico spazio di Hilbert tra gli $L^p$.
\end{proposition}

\begin{definition}{Sistema ortonormale completo}{}
    Sia $H$ uno spazio di Hilbert. Un insieme $\beta$ di vettori si dice \bemph{sistema ortonormale} se per ogni coppia di vettori $x_i, x_j \in \beta$ si ha $x_i \cdot x_j = \delta_{i,j}$.\\
    Se preso un vettore $v \in H$ si abbia  che $v\cdot x = 0$ per ogni $x \in \beta$ implichi che $v=0$, allora $\beta$ si dice \bemph{sistema ortonormale completo} in $H$.
\end{definition}

\subsection{Teoria $L^2$ delle serie di Fourier}

\begin{theorem}{Corollario del teorema di Stone-Weierstrass}{}
    Consideriamo lo spazio di Hilbert $L^2([-\pi,\pi], \M_{\L^1}, \L^1)$ che scriveremo spesso come $L^2(-\pi,\pi)$ per semplicità. La famiglia 
    \[ \left\{ \frac{1}{\sqrt{2\pi}}\right\} \cup \left\{ \frac{\sin(nx)}{\sqrt{2\pi}} \right\}_{\Z^+} \cup \left\{ \frac{\cos(nx)}{\sqrt{2\pi}} \right\}_{\Z^+} \]
    è un sistema ortonormale completo.
\end{theorem}

\begin{definition}{Serie di Fourier}{}
    Sia $f \in L^2(-\pi,\pi)$ e siano $a_n, b_n\in \R$ definiti come segue:
    \[a_n = \frac{1}{\pi} \int_{[-\pi,\pi]} f(t) \cos(nt) \de \L^1(t) \quad \text{per } n \in \N, \quad \quad b_n = \frac{1}{\pi} \int_{[-\pi,\pi]} f(t) \sin(nt) \de \L^1(t) \quad \text{per } n \in \Z^+ \]   
    E siano
    \[S_{2N+1} := \frac{a_0}{2} + \sum_{n=1}^{N} a_n \cos(nx) + b_n\sin(nx), \quad S_f:=\lim_{N \to +\infty} S_{2N+1}\]
    Allora $S_f$ si dice \bemph{serie di Fourier} di $f$ 
\end{definition}

\begin{theorem}{Convergenza di serie di Fourier}{}
    Sia $f \in L^2(-\pi,\pi)$.\\ La serie di Fourier $S_f$ di $f$ converge incondizionatamente a $f$.
\end{theorem}

\begin{theorem}{Lusin-Carleson}{}
    Sia $f \in L^2(-\pi,\pi)$.\\
    La serie di Fourier $S_f$ di $f$ converge puntualmente a $f$ per $\L^1$-quasi ogni $x \in ]-\pi,\pi[$.
\end{theorem}

\subsection{Convergenza puntuale della serie di Fourier per funzioni regolari a tratti}

\begin{definition}{Funzione continua e regolare a tratti}{}
    Sia $f:\R \to \R$ una funzione $2\pi$-periodica. Se \begin{itemize}
        \item L'insieme $D \subset [-\pi,\pi[$ delle discontinuità di $f$ è finito e formato da discontinuità al massimo di salto, $f$ si dice \bemph{continua a tratti}.
        \item $f$ è continua a tratti e $f$ è $\mc{C}^1$ in almeno $[-\pi,\pi[\setminus D$, allora $f$ si dice \bemph{regolare a tratti}.
    \end{itemize}
    In particolare, per $x_0 \in \R$ definiamo
    \[f(x_0\pm 0) = \lim_{x \to x_0^\pm} f(x)\]
    Entrambi esistenti e finiti per definizione.
\end{definition}

\begin{theorem}{Convergenza puntuale e uniforme della serie di Fourier}{}
    Sia $f:\R\to\R$ una funzione $2\pi$-periodica regolare a tratti. Allora:\begin{enumerate}
        \item Per ogni $x \in \R$ si ha che $S_f(x)$ è uguale alla media tra $f(x-0)$ e $f(x+0)$ e in particolare se $f$ è continua in $x$ si ha $S_f(x) = f(x)$.
        \item $S_f$ converge uniformemente a $f$ in tutti gli intervalli chiusi in cui $f$ è continua.
        \item Se $f$ è continua su tutto $\R$, allora $S_f$ converge uniformemente a $f$ su tutto $\R$.
    \end{enumerate}
\end{theorem}

\begin{remark}{Serie di Fourier di funzioni pari e dispari}{}
    Consideriamo $f:\R\to\R$ regolare a tratti e la sua serie di Fourier $S_f$.\begin{itemize}
        \item Se $f$ è pari, $b_n = 0$ per ogni $n \in \Z^+$.
        \item Se $f$ è dispari, $a_n = 0$ per ogni $n \in \N$.
    \end{itemize}
\end{remark}

\section{Successioni e serie di funzioni}

\subsection{Successioni di funzioni}

\begin{definition}{Insieme di convergenza puntuale}{}
    Sia $\{f_n :X_n\to\R\}_\N$ una successione di funzioni. Definiamo l'insieme $D$ e la funzione $f$ come seguono:
    \[D_f := \left\{\forall n>\hat{n}, x \in X_n | \lim_{n\to+\infty} f_n(x) = l_x \in \R \right\} \quad f : x\in D_f \mapsto l_x\]
    Allora $D_f$ si dice \bemph{insieme di convergenza puntuale} di $\{f_n\}_\N$ e $f$ si dice \bemph{limite puntuale} di $\{f_n\}_\N$ e scriviamo $f_n \to f$ in $D_f$.
\end{definition}
    
\begin{definition}{Convergenza uniforme}{}
    Sia $\{f_n :X_n\to\R\}_\N$ una successione di funzioni e sia $E$ tale che $E \subset X_n$ definitivamente. Posti $f$ e $D_f$ come sopra, si dice che $\{f_n\}_\N$ converge uniformemente a $f$ in $E$ se $E\subset D_f$ e vale
    \[\lim_{n\to +\infty} \sup_E|f_n - f| = 0\]
\end{definition}

\begin{remark}{Occhio alle implicazioi}{}
    La convergenza uniforme in un insieme implica la convergenza puntuale nello stesso, ma non viceversa.\\
    La continuità in un sottoinsieme implica la continuità della restrizione, ma non viceversa.
\end{remark}

\begin{theorem}{Convergenza uniforme e continuità}{}
    Sia $\{f_n : X \to \R\}$ una successione di funzioni che converge uniformemente in $E\subset X$ a $f$. Se si ha che (definitivamente) le funzioni $f_n|_E$ sono continue, allora anche $f|_E$ è continua.
\end{theorem}

\begin{theorem}
    Sia $f \in \mc{C}^\infty(]a,b[)$ con $a,b \in \R$ tale che esista una costante $K \in \R$ che elevata alla $n$ limiti superiormente la derivata $n$-esima di $f$ su $]a,b[$ per $n$ sufficientemente grande.\\
    Allora il polinomio di taylor di $f$ conferge uniformemente a $f$.
\end{theorem}

\begin{proposition}{Passaggio al limite sotto il segno di integrale}{}
    Sia $\{f_n\}_\N$ una successione di funzioni continue su $[a,b]$ uniformemente convergente a $f$. Vale
    \[\lim_{n\to+\infty}\int_{[a,b]}f_n \de \L^1 = \int_{[a,b]} f \de \L^1\]
\end{proposition}

\subsection{Serie di funzioni generiche}

\begin{definition}{Convergenza semplice e totale}{}
    Sia $(V,||\cdot||)$ uno spazio vettoriale normato e $\{v_i\}_\N$ una successione di vettori.\\
    Diremo che la serie $\sum v_i$ \bemph{converge semplicemente} se converge in senso usuale in $V$, mentre diremo che la serie \bemph{converge totalmente} se la serie $\sum ||v_i||$ converge in $\R$.
\end{definition}

\begin{remark}{}{}
    In uno spazio di Banach, la convergenza totale implica la convergenza semplice, non necessariamente viceversa.
\end{remark}

\begin{proposition}{}{}
    Sia $[a,b]\subset \R$ e sia $\{f_n\}_\N$ in $\mc{C}^0([a,b])$ una successione che converga semplicemente. Allora vale
    \[\int_{[a,b]} \sum_{n\in\N} f_n \de \L^1 =\sum_{n\in\N}  \int_{[a,b]} f_n \de \L^1\]
\end{proposition}

\subsection{Serie di potenze}

\begin{proposition}{}{}
    Data una successione $\{a_n\}_\N$ di numeri reali e la serie di potenze $\sum a_n x^n$, consideriamo il suo insieme di convergenza puntuale $D$ e $R:=\sup_D(|x|)$. Allora valgono le seguenti:\begin{itemize}
        \item $0 \in D$ e $D = \{0\}$ se e solo se $R=0$
        \item Se $R>0$, per ogni $0<r<R$ la serie converge totalmente in $[-r,r]$
        \item Vale $]-R,R[ \subset D \subset [-R,R]$, per questo $R$ è detto \bemph{raggio di convergenza} della serie
        \item Se $R>0$, la funzione $x\mapsto \sum a_nx^n$ è continua su $]-R,R[$
    \end{itemize}
\end{proposition}

\begin{theorem}{Raggio di convergenza}{}
    Sia una serie di potenze $\sum a_nx^n$ con raggio di convergenza $R$ e poniamo:
    \[\rho := \limsup_{n\to+\infty} \sqrt[n]{|a_n|}\] 
    Allora $R= 1/\rho$ (con estensione a $0$ e $+\infty$). Inoltre se, per $n$ sufficientemente grandi, $a_n \neq 0$ ed esiste il limite
    \[l = \lim_{n\to+\infty}\left|\frac{a_{n+1}}{a_n}\right|\]
    Allora si ha $\rho = l$.
\end{theorem}

\begin{remark}{}{}
    Data una serie di potenze $\sum a_nx^n$ con raggio di convergenza $R>0$, si possono verificare questi casi:
    \[D = ]-R,R[ \quad D = ]-R,R] \quad D = [-R,R[ \quad D = [-R,R]\]
\end{remark}

\section{Foglio antipanico}

\begin{example}{Serie geometrica}{}
    Può essere utile ricordare la serie geometrica di ragione $q \in ]-1,1[$
    \[\sum_{n \in \N} q^n = \frac{1}{1-q}\]
\end{example}

\subsection{Sviluppi di Taylor e derivate}

\begin{example}{Funzioni trigonometriche}{}
    Vale la pena ricordare le derivate prime delle funzioni trigonometriche
    \[\sin'(x) = \cos(x) \quad \cos'(x) = -\sin(x) \quad \tan'(x) = \frac{1}{\cos^2(x)} \quad \arcsin'(x) = \frac{1}{\sqrt{1-x^2}} \quad \arctan'(x) = \frac{1}{1+x^2}\] 
    E i loro sviluppi di Taylor centrati in $x=0$.
    \[\sin(x) = \sum_{n\in\N} \frac{(-1)^nx^{2n+1}}{(2n+1)!} \quad \cos(x) = \sum_{n\in\N} \frac{(-1)^nx^{2n}}{(2n)!} \quad \arctan(x) = \sum_{n\in\N} \frac{(-1)^n x^{2n+1}}{2n+1}\]
\end{example}

\begin{example}{Funzioni esponenziali}{}
    Vale la pena ricordare le derivate prime delle funzioni esponenziali
    \[\exp'(x) = \exp(x) \quad \log'(x) = \frac{1}{x} \quad \sinh'(x) = \cosh(x) \quad \cosh'(x) = \sinh(x)\]
    E i loro sviluppi di Taylor centrati in $x=0$
    \[e^x = \sum_{n\in\N} \frac{x^n}{n!} \quad \log(1+x) = \sum_{n \in \Z^+} -\frac{(-x)^n}{n} \quad \sinh(x) = \sum_{n\in\N} \frac{x^{2n+1}}{(2n+1)!} \quad \cosh(x)= \sum_{n\in\N} \frac{x^{2n}}{(2n)!}\]
\end{example}

\begin{example}{Funzioni razionali}{}
    Vale la pena ricordare lo sviluppo di Taylor di qualche funzione razionale
    \[\frac{1}{1-x} = \sum_{n\in\N} x^n \quad \frac{1}{1+x^2} = \sum_{n\in\N} (-1)^n x^{2n}\]
\end{example}

\subsection{Trigonometria}

\begin{example}{Identità trigonometriche}{}
    Qualche identità trigonometrica 
    \[\sin(x) = \frac{\tan(x)}{\pm\sqrt{1+\tan^2(x)}} \quad \cos(x) = \frac{1}{\pm\sqrt{1+\tan^2(x)}}\]
    Le formule di addizione
    \[\cos(x\pm y) = \cos x \cos y \mp \sin x \sin y \quad \sin(x\pm y) = \sin x \cos y \pm \cos x \sin y \quad \tan(x \pm y) = \frac{\tan x \pm \tan y}{1 \mp \tan x \tan y}\]
    Le formule di duplicazione
    \[\sin(2x) = 2\sin x \cos x \quad \cos(2x) = \cos^2 x - \sin^2 x = 1-2\sin^2 x = 2\cos^2 x -1 \quad \tan(2x) = \frac{2\tan x}{1- \tan^2 x}\]
    Le formule di bisezione
    \[\sin\left(\frac{x}{2}\right) = \pm\sqrt{\frac{1-\cos x}{2}} \quad \cos\left(\frac{x}{2}\right) = \pm\sqrt{\frac{1+\cos x}{2}} \quad \tan\left(\frac{x}{2}\right) = \pm\sqrt{\frac{1-\cos x}{1+\cos x}} = \frac{\sin x}{1 + \cos x} = \frac{1 - \cos x}{\sin x}\]
    Le formule parametriche
    \[t := \tan \left(\frac{x}{2}\right) \Rarr \sin x = \frac{2 t}{1 + t^2} \quad \cos x = \frac{1 - t^2}{1+t^2}\]
\end{example}

\subsection{Flowcharts}

\begin{example}{Esercizio standard sulle serie di Fourier}{}
    Sia $f:A\to\R$ una funzione $2\pi$-periodica la cui espressione $f(x)$ è data per $[-\pi,\pi[$ e indichiamo con $S_f$ la sua serie di Fourier in astratto.
    \begin{enumerate}
        \item Prima di tutto controlliamo le simmetrie di $f$, che ci possono aiutare col grafico e più tardi coi coefficienti di $S_f$:\begin{itemize}
            \item Se $f$ è pari, ovvero $f(x) = f(-x)$, abbiamo che il suo grafico è simmetrico rispetto all'asse $y$ e che (se $f$ è regolare a tratti) per ogni $n\in\Z^+$ abbiamo $b_n=0$.
            \item Se $f$ è dispari, ovvero $f(x)=-f(-x)$, abbiamo che il suo grafico è simmetrico rispetto all'origine e che (se $f$ è regolare a tratti) per ogni $n\in\N$ abbiamo $a_n=0$.
        \end{itemize}
        \item Poi disegnamo il grafico di $f$ su $[-\pi,\pi[$
        \item Verifichiamo la continuità a tratti di $f$ e calcoliamo il suo insieme di discontinuità $D\subset [-\pi,\pi[$ e i limiti $f(x+0)$ e $f(x-0)$ per ogni $x\in D$.
        \item Verifichiamo che $f$ sia $L^2(-\pi,\pi)$ per ottenere i seguenti risultati:\begin{itemize}
            \item $S_f$ converge incondizionatamente a $f$ in $(L^2(-\pi,\pi),||\cdot||_2)$.
            \item $S_f$ converge puntualmente a $f$ per $\L^1$-quasi ogni $x \in ]-\pi,\pi[$.
        \end{itemize}
        \item Verifichiamo la regolarità a tratti per ottenere i seguenti risultati:\begin{itemize}
            \item $S_f$ converge puntualmente a $f$ in $\R\setminus D$.
            \item $S_f$ converge alla media dei limiti destro e sinistro in $D$.
            \item $S_f$ converge uniformemente a $f$ negli intervalli chiusi in cui $f$ è continua.
        \end{itemize}
        \item Calcoliamo i coefficienti $\{a_n\}_\N$ e $\{b_n\}_{\Z^+}$ di $S_f$ con le formule:
        \[a_n = \frac{1}{\pi}\int_{[-\pi,\pi]} f(t) \cos(nt) \de\L^1(t) \quad b_n = \frac{1}{\pi}\int_{[-\pi,\pi]} f(t) \sin(nt) \de\L^1(t)\]
        Ricordandoci le regolarità e simmetrie di cui sopra per facilitarci i calcoli.
    \end{enumerate}
\end{example}


\end{document}