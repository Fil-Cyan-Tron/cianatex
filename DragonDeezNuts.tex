\documentclass{book}
\usepackage[pastel]{cianatex}

\title{Fondamenti di Fisica Matematica - Modulo 2}
\author{Filippo $\L$. Troncana \\ \footnotesize Trascrizione in \LaTeX\ del riassunto di Matilde Calabri delle note del prof. Nicolò Drago, rivisitazione delle note del prof. Valter Moretti}
\date{A.A. 2023/2024}

\begin{document}

\maketitle


\section*{Prefazione}
    
Tra noi studenti del corso di laura in Matematica dell'università degli studi di Trento, il professor Valter Moretti ha la fama di essere il professore dalla notazione più ostica e dai contacci più inverecondi.\\
Ahinoi, il suo discepolo Nicolò Drago\footnote{Detto Nick Drake in questa trattazione} si è dimostrato all'altezza di raccogliere tale eredità e purtroppo sembra che la nostra collega Matilde si stia incamminando lungo l'oscuro cammino della setta dei fisici matematici genovesi.\\
Al fine di salvaguardare la mia e vostra sanità mentale\footnote{Nonchè impedire l'ulteriore arricchimento di avidi oculisti}, ho deciso di provvedere (ovunque e nella misura in cui mi fosse possibile) allo snellire la notazione, usando il \bemph{poco noto} fatto che il prodotto tra matrici può essere calcolato anche senza esplicitare ciascun termine.\\
Qualcuno potrebbe insinuare che dietro a questa macelleria notazionale ci possa essere un'inadeguata capacità di svolgere i calcoli\footnote{E avrebbe ragione}, ma l'opinione del sottoscritto è che lavorando in spazi vettoriali con una dimensione maggiore di $2$, esplicitare le coordinate equivalga ad un autosabotaggio.\\
Pertanto rimango convinto che sebbene ogni tanto questo sforzo di condensazione avrà sicuramente introdotto qualche errore, il beneficio in termini di leggibilità sia soverchiante.\\
Buono studio a tutti voi, a morte i multi-indici e a morte la notazione di Einstein per le matrici.

\tableofcontents

\section{Introduzione}

\begin{definition}{Supporto}{}
    Sia $X$ uno spazio topologico e $f:X\to\C$ una mappa.\\
    Si dice \bemph{supporto} di $f$ l'insieme $\{x\in X : f(x)\neq 0\}$ e lo indichiamo come $\supp(f)$
\end{definition}
\begin{notation}
    Sia $X$ uno spazio topologico e $A\subset X$ un aperto. Denotiamo con $\bar{A}$ la chiusura di $A$.
\end{notation}

\begin{remark}{}{}
    $x \in \supp(f) \Rarr f(x)\neq 0$.
\end{remark}

\begin{definition}{Funzione differenziabile}{}
    Sia $\Omega\subset \R^n$ un aperto non vuoto, sia $f:\Omega\to\R^m$ una funzione e sia $x_0\in\Omega$.\\
    $f$ si dice \bemph{differenziabile} in $x_0$ se esiste una mappa lineare $L_{x_0} : \Omega\to\R^m$ tale che:
    \[\lim_{||h||_n \to 0} \frac{||f(x_0 + h) - f(x_0) - L_{x_0}(h)||_m}{||h||_n} = 0\]
\end{definition}

\begin{remark}{}{}
    Sia $\{e_i\}_1^n$ la base canonica di $\R^n$. Ponendo $h=e_j$, la differenziabilità di $f$ in $x_0$ implica l'esistenza della derivata parziale di $f$ lungo la direzione $e_j$ in $x_0$ e che $L_{x_0} = \nabla f (x_0)$.
\end{remark}

\begin{remark}{}{}
    Al contrario, l'esistenza delle derivate parziali non implica la differenziabilità.
\end{remark}

\begin{proposition}{}{}
    Sia $\Omega$ un aperto di $\R^n$ e sia $f:\Omega\to\R^m$ una funzione tale che esistano e siano continue le derivate parziali in $x_0\in\Omega$.\\
    Allora $f$ è differenziabile in $x_0$
\end{proposition}

\begin{definition}{$\mc{C}^k$-differenziabilità}{}
    Sia $\Omega$ un aperto di $\R^n$ e sia $f:\Omega\to\R^m$.\\
    $f$ è $\mc{C}^k(\Omega)$, o $\mc{C}^k$\bemph{-differenziabile} su $\Omega$ se esistono continue tutte le derivate miste di ordine $k$ su $\Omega$.
\end{definition}

\begin{notation}
    Indichiamo con $\mc{C}_c^k(\Omega)$ lo spazio delle funzioni $\mc{C}^k$-differenziabili a supporto compatto.
\end{notation}

\begin{remark}{}{}
    $\mc{C}^k(\Omega)$ e $\mc{C}_c^k(\Omega)$ sono $\R$-spazi vettoriali
\end{remark}

\begin{definition}{}{}
    Le funzioni contenute in $\mc{C}^\infty(\Omega) = \bigcap \mc{C}^k(\Omega)$ sono dette funzioni lisce (a supporto compatto se il loro supporto è compatto). 
\end{definition}

\begin{definition}{Differenziabilità su un chiuso}{}
    Sia $\Omega$ un aperto di $\R^m$ e sia $\bar{\Omega}$ la sua chiusura.\\
    Una funzione $f:\bar{\Omega}\to\R^m$ si dice $\mc{C}^k$\bemph{-differenziabile} su $\bar{\Omega}$ se le derivate di ordine $k$ sono estendibili con continuità a $\bar{\Omega}$.
\end{definition}

\begin{notation}
    Sia $\Omega \in \R^n$ un aperto e sia $f:\Omega \to \R$ una funzione derivabile due volte su $\Omega$. Denotiamo
    \[H_f(x):=\begin{pmatrix}
        \frac{\partial^2 f}{\partial x_1^2}(x) &\dots & \frac{\partial^2 f}{\partial x_n\partial x_1}(x)\\
        \vdots & \ddots & \vdots \\
        \frac{\partial^2 f}{\partial x_1\partial x_n}(x) &\dots & \frac{\partial^2 f}{\partial x_n^2}(x)
    \end{pmatrix}\]
    Se $f \in \mc{C}^2(\Omega)$ allora $H_f(x)$ è simmetrica.
\end{notation}

\begin{notation}
    Siano $A = (a_{i,j})$ e $B = (b_{i,j})$ due matrici $n\times n$ sullo stesso campo $\K$. Useremo queste convenzioni:
    \[A\times B = (c_{i,j}) = \sum_{r=1}^{n} a_{i,r} b_{r,j} \in M_{n\times n}(\K) \quad \text{e} \quad A\cdot B = \sum_{i = 1}^{n} \sum_{j=1}^{n} a_{i,j} b_{i,j} \in \K\]
\end{notation}


\begin{definition}{Operatore differenziale semilineare del secondo ordine}{ODS2}
    Un operatore $D:\mc{C}^2(\Omega) \to \mc{C}^0(\Omega)$ si dice \bemph{semilineare del secondo ordine} se può essere scritto come $(Du)(x) = A(x)\cdot H_u(x) + \Phi(x,u(x), \nabla u(x))$ per qualsiasi $u \in \mc{C}^2(\Omega)$, dove $A(x)$ è una matrice simmetrica che dipende con continuità da $x\in\Omega$ e $\Phi$ dipende con continuità dai suoi parametri.
\end{definition}

\begin{definition}{Equazione differenziale alle derivate parziali semilineare}{}
    Si dice \bemph{equazione differenziale alle derivate parziali semilineare} un'equazione con incognita $u$ della forma $Du = f$ dove $D$ è un operatore differenziale semilineare dato e $f$ è una funzione data.
\end{definition}

\begin{remark}{}{}
    La definizione di \href{def:ODS2}{operatore differenziale semilineare del secondo ordine} si può generalizzare in due modi:\begin{itemize}
        \item a funzioni a valori vettoriali, anche complessi, ma richiediamo che $A$ e $\Phi$ abbiano comunque valore reale.
        \item a ordini $k$ arbitrari sostituendo a $H_u$ e $\nabla u$  rispettivamente il tensore derivata\footnote{Semplicemente, il tensore in cui l'elemento di multi-indice $\alpha = (i,...,j)$ corrisponde alla derivata mista delle direzioni $x_i,...,x_j$} di ordine $k$ e i tensori derivata fino all'ordine $k-1$.
    \end{itemize}
    Nel caso in cui $\Phi$ dovesse essere dipendente in modo lineare da $u$ e $\nabla u$, l'operatore si direbbe \bemph{lineare} come l'equazione associata.\\
    Si può anche parlare di operatori quasilineari, in cui $A = A(x,u(x),\nabla u(x))$, e delle equazioni associate.\\
    Vale la pena notare che questi operatori siano tutti locali, e che non dipendano da proprietà globali della funzione come ad esempio il suo integrale su $\Omega$.
\end{remark}

\begin{definition}{Diffeomorfismo}{}
    Dati due aperti $\Omega\subset \R^n$ e $\Omega'\subset \R^m$, si dice \bemph{diffeomorfismo} di ordine $k$ una funzione $f:\Omega \to \Omega'$ $k$-differenziabile e invertibile con inversa $k$-differenziabile.
\end{definition}

\begin{theorem}{Invertibilità locale}{}
    Siano $\Omega$ e $\Omega$ due aperti di $\R^n$ e $f:\Omega\to\Omega'$ una funzione $k$-differenziabile con $\det J_f \neq 0$ su $\Omega$.\\
    Allora $f$ è un $k$-diffeomorfismo tra $\Omega$ e $\Omega'$.
\end{theorem}

\begin{corollary}{}{}
    Sia $\Omega$ un aperto di $\R^n$ e sia $f:\Omega\to\R^n$ una funzione $k$-differenziabile tale che $\det J_f \neq 0$ su $\Omega$.\\
    Allora $f(\Omega)$ è un aperto e se $f$ è iniettiva allora è un $k$-diffeomorfismo.
\end{corollary}

\begin{lemma}{}{}
    Sia $D:\mc{C}^2(\Omega)\to\mc{C}^0(\Omega)$ un operatore differenziale del secondo ordine semilineare e sia $\tilde{x} : \Omega \to \tilde{\Omega}$ un diffeomorfismo e per ogni $u \in \mc{C}^2(\Omega)$ sia $\tilde{u} := u\circ \tilde{x} \in \mc{C}^2(\tilde{\Omega})$. Allora:\begin{itemize}
        \item $Du = 0 \Rarr \tilde{D}\tilde{u} = 0$, dove $\tilde{D}$ è definito come $D(\tilde{x}^{-1}\circ \tilde{u})$.
    \end{itemize}
\end{lemma}

\begin{remark}{}{}
    Sotto cambiamenti di coordinate come nel lemma precedente, abbiamo che $A$ si trasforma in modo tensoriale, a differenza di $\Phi$, per questo sarà detto \bemph{simbolo principale} di $D$.
\end{remark}

\begin{definition}{Operatori ellittici, iperbolici e parabolici}{}
    Sia $\Omega$ un aperto di $\R^m$ $D:\mc{C}^2(\Omega)\to\mc{C}^0(\Omega)$ un operatore differenziale semilineare del secondo ordine e sia $A$ il suo simbolo principale. Siano $(n_+,n_-,n_0)$ i numeri rispettivamente degli elementi positivi, negativi e nulli sulla diagonale di $A$ (assumiamo $\Omega$ abbastanza piccolo perchè questi siano costanti).\begin{itemize}
        \item Se $n_+ = m$ o $n_- = m$, $D$ si dice \bemph{ellittico}.
        \item Se $n_0=0$, $D$ si dice \bemph{iperbolico}.
        \item Se $n_+ = 1$ e $n_- = m-1$ oppure $n_+ = m-1$ e $n_- = 1$, allora $D$ si dice \bemph{normalmente iperbolico}.
        \item Se $n_0 \neq 0$ e $n_+ = m-n_0$ oppure $n_- = m-n_0$, allora $D$ si dice \bemph{parabolico}
        \item Se è parabolico e $n_0 = 1$, allora si dice \bemph{normalmente parabolico}.
    \end{itemize}
    Lo stesso vale per le equazioni associate.
\end{definition}

\section{Esempi di operatori differenziali del secondo ordine semilineari}

\begin{example}{Operatore delle onde, o di D'Alembert}{}
    Consideriamo funzioni a valori reali di un vettore $x$ di $n$ coordinate spaziali e del tempo $t$.\\
    L'operatore delle onde (a cui è associata l'equazione delle onde):
    \[ D(u) := \left(\frac{1}{c^2}\frac{\partial^2}{\partial t^2} - \Delta_x\right) u \quad \text{dove}\quad \Delta_x u := \frac{\partial^2 u}{\partial x_1^2} +...+ \frac{\partial^2 u}{\partial x_n^2}\]
    Ha simbolo principale non-zero solo sulla diagonale, che ha la forma $(c^{-2},-1,...,-1,)$, dunque è iperbolico.
\end{example}

\begin{example}{Operatore di Helmholtz}{}
    Dall'equazione delle onde, assumiamo una soluzione $u(t,x)$ della forma $e^{i\omega t}v(x)$\\
    Allora l'operatore $e^{i\omega t}(\lambda + \Delta)$ è un operatore ellittico con $\lambda>0$ ed è detto operatore di Helmholtz.
\end{example}

\begin{example}{Operatore di Laplace normale e massivo}{}
    Come visto sopra, l'operatore di Laplace:
    \[\Delta u := \frac{\partial^2 u}{\partial x_1^2} +...+ \frac{\partial^2 u}{\partial x_n^2}\]
    Ha diagonale $(1,...,1)$, come l'operatore di Laplace massivo $(\Delta - \eta^2)$, dunque è ellittico.
\end{example}

\begin{example}{Operatore del calore}{}
    L'operatore del calore:
    \[\frac{1}{\sigma^2} \frac{\partial}{\partial t} - \Delta_x\]
    È un operatore parabolico avendo diagonale $(0,-1,...,-1)$
\end{example}

\section{Un poco di geometria differenziale}

\begin{definition}{Ipersuperficie $k$-regolare}{}
    Sia $\Sigma$ un sottoinsieme di $\R^n$.\\
    $\Sigma$ si dice \bemph{ipersuperficie regolare} di ordine $k$ se è localmente luogo di zeri di funzioni $k$-differenziabili con gradiente non-nullo.
\end{definition}

\begin{remark}{}{}
    La non-nullità del gradiente delle funzioni che definiscono $\Sigma$ è invariante per cambiamenti di coordinate, e in particolare abbiamo che rappresenta il vettore normale alla superficie.
\end{remark}

\begin{definition}{Ipersuperficie orientabile}{}
    Un'ipersuperficie $\Sigma\subset\R^n$ è detta \bemph{orientabile} se esiste un campo vettoriale definito su $\Sigma$ tale che questo sia unitario e sempre normale a $\Sigma$. 
\end{definition}

\begin{definition}{}{}
    Sia $\Omega$ un aperto non vuoto di $\R^n$ tale che $\partial\Omega$ sia un'ipersuperficie $1$-regolare.\\
    Diciamo che un campo vettoriale $v$ \bemph{punta verso l'esterno} di $\Omega$ se è localmente il gradiente normalizzato di una funzione $S\in\mc{C}^1$  tale che $S(\partial\Omega) = \{0\}$ e $S(\Omega) = ]-\infty,0[$.
\end{definition}

Il teorema seguente è fondamentale per dotare un'ipersuperficie $k$-regolare di un sistema di coordinate speciali dette normali di Riemann.

\begin{theorem}{Teorema della funzione implicita}{}
    Sia $\Omega$ un aperto di $\R^n$, sia $f \in \mc{C}^k(\Omega)$ tale che per $x_0 \in \Omega$ si abbia $\partial_{x^i} f(x_0)\neq 0$. Inoltre per $x\in\R^n$ scriviamo $x = x^1e_1 + \hat{x}$\\
    Allora esistono intorni aperti $\U_{x_0^1}$ dove $x_0 = x_0^1 e_1 + \hat{x_0}$ e $\U_{\hat{x}_0}$ tale che $\U_{x_0^1}\times\U_{\hat{x}_0}\subset\Omega $ ed esiste un'unica $g\in\mc{C}^k(\U_{\hat{x}_0})$ tale che $f(g(\hat{x}),\hat{x}) = f(x)$ su tutto $\U_{\hat{x}_0}$.
\end{theorem}

\begin{remark}{}{}
    Per l'invarianza di $\nabla S \neq 0$ per cambiamenti di coordinate, d'ora in poi possiamo sempre assumere $x_0 = 0$ e che $\nabla S$ sia parallelo a $e_1$.\\
    Questo implica anche che $g(0)=0$ e le sue derivate parziali in $\hat{x_0}$ siano nulle
\end{remark}

Con una stramarea di calcoli magici incredibili arriviamo alle \bemph{coordinate normali di Riemann} $(t,\hat{x})$ tali che su $\Sigma$ si abbia (localmente) $t=0$ e alla \bemph{misura di Lebesgue indotta} (detta misura di Hausdorff dagli esperti). 

Siano $(t,\xi)$ le coordinate di Riemann definite su un aperto $\U \subset \R^n$, assumiamo che $\U=I\times\U_\Sigma$ e sia $f \in \mc{C}_c^0(\U)$ con supporto contenuto in $\U$. Se $x(t,\xi)$ è un cambiamento di coordinate e $J_x(t,\xi)$ il suo jacobiano, denotando $\tilde{f}(t,\xi) = f(x(t,\xi))$ allora vale:

\[\int\limits_{\R^n} f(x)\de^n x = \int\limits_I \int\limits_{\U_\Sigma} \tilde{f}(t,\xi) \cdot J_x(t,\xi) \de\xi\de t \]

Dato che $f$ è continua possiamo considerare l'integrale

\[\int\limits_\Sigma f_\Sigma(y) \de S(y) = \int\limits_{\U_\Sigma}\tilde{f}(0,\xi) \cdot J_x(0,\xi) \de\xi\]

Questo definisce per "incollamento"\footnote{Non venite a chiedere a me cosa cazzo significhi} una misura sulla $\sigma$-algebra boreliana di $\Sigma$ con la topologia indotta. Quando $\Sigma$ è chiusa e orientata, denotiamo l'integrale di cui sopra con $\oint\limits_{+\Sigma}$, dove il segno definisce l'orientazione presa in esame.

Adesso ci sarebbe tutta una bella parte sul calcolo del volume o della superficie dell'ipersfera ma Dio sa che non frega nulla nè a me nè a voi.

\section{Il problema di Cauchy per PDE locali}

Consideriamo una PDE locale del secondo ordine della forma $F(x,u(x),\nabla u(x), H_u(x)) = 0$ con $F$ continua.

\begin{definition}{Problema di Cauchy}{}
    Sia $\Omega$ un aperto di $\R^n$ non vuoto e $\Sigma$ una $k$-ipersuperficie regolare orientabile con normale unitaria $\nu$.\\
    Il \bemph{problema di Cauchy} per $F$ con dati in $\Sigma$ consiste nell'individuare $u$ tale che:
    \[F(x,u(x),\nabla u(x), H_u(x)) = 0 \quad u|_\Sigma = u_0 \quad \frac{\partial u}{\partial \nu}\big{|}_\Sigma = (\nu \cdot \nabla u)|_\Sigma = u_1\]
    Dove $u_0 \in \mc{C}^2(\Sigma)$ e $u_1 \in \mc{C}^1(\Sigma)$ sono date.
\end{definition}

Osserviamo che la regolarità richiesta di $u$ è compatibile con le regolarità date di $u_0$ e $u_1$.

\begin{definition}{Buona positura nel senso di Hadamard}{}
    Un problema di Cauchy (come sopra) si dice \bemph{ben posto nel senso di Hadamard} se la soluzione $u$ esiste, è unica e se una piccola variazione dei dati porta a una piccola variazione delle soluzioni, formalmente se fissata una topologia (ad esempio la convergenza puntuale) abbiamo che delle successioni $\{u_{0,n}\}_\N\to u_0$ e $\{u_{1,n}\}_\N\to u_1$ inducono una successione $\{u_n\}_\N\to u$.\\
    Se almeno una delle condizioni non è rispettata, il problema si dice \bemph{mal posto}.
\end{definition}

\begin{remark}{}{}
    La condizione di esistenza e unicità della soluzione è abbastanza una speranza naturale, mentre la condizione di piccola variazione è importante in molte applicazioni nel mondo reale perchè abbiamo sempre un qualche tipo di incertezza nelle misure; questa aspettativa potrebbe essere comunque tradita esaminando sistemi caotici, ma non sono nello scopo di questo corso.\\
    È in effetti una condizione un po' ambigua in quanto dipendente dalla scelta di una topologia, ma è una scelta che va fatta caso per caso.
\end{remark}

\begin{example}{PDC mal posto}{}
    Consideriamo il problema di Cauchy in $\R^2$:
    \[\Delta u = 0 \quad u(x,0) = u_0(x) \quad \frac{\partial u}{\partial y}(x,0) = u_1(x)\]    
    Con dati iniziali
    \[u_{0,n}(x) = 0 \quad u_{1,n} = \frac{\sin(nx)}{n} \]
    Fidandoci del nostro profeta Nick Drake che ci dice che è mal posto, concludiamo che è mal posto.
\end{example}

\begin{notation}
    Ogni volta che dovremo fidarci del profeta Nick Drake useremo il simbolo \Nick.
\end{notation}

\begin{notation}
    Sia $x = (t,\hat{x})$ e $A(x)$ la matrice dei soliti operatori semilineari vattelappesca.\\
    Indichiamo con $A_t(x)$ la riga di $A$ attinente alle derivate su $t$ di ciascuna derivata su $\hat{x}_i$ e $A_{\hat{x}}(x)$ la sottomatrice attinente alle derivate spaziali miste.
\end{notation}

\begin{definition}{PDC in forma normale}{}
    Consideriamo il problema di Cauchy (con $x = (t,\hat{x})$ in coordinate di Riemann sulla superficie $\Sigma$):
    \[A(x)\cdot H_u(x) + \Phi(x, u(x), \nabla u(x)) = 0 \quad u(0,\hat{x}) = u_0(\hat{x}) \quad \frac{\partial u}{\partial t}(0,\hat{x}) = u_1(\hat{x})\]
    Questo si dice \bemph{in forma normale} se l'equazione può essere riscritta come:
    \[\frac{\partial^2 u}{\partial t^2} = A_t(x) \cdot \frac{\partial \nabla_{\hat{x}} u }{\partial t}(x) - A_{\hat{x}}(x) \cdot H_{u,\hat{x}}(x) - \Phi\left(x,u(x),\frac{\partial u}{\partial t}(x), \nabla_{\hat{x}} u(x) \right)\]
\end{definition}

\begin{definition}{Funzione analitica}{}
    Sia $f \in \mc{C}^\infty(\Omega)$. Diremo che $f\in\mc{C}^\omega(\Omega)$, ovvero che $f$ è \bemph{analitica} in $\Omega$ se la sua serie di Taylor è assolutamente convergente a $f$ in $\Omega$\footnote{Nick questa cosa la esprime formalmente in modo inverecondo quindi con permesso io decido di ometterla}.
\end{definition}

\begin{theorem}{Teorema di Cauchy-Kovalevskaja}{C-K}
    Si consideri un problema di Cauchy in forma normale come sopra tali che tutti i dati (vale a dire $u_0$, $u_1$, $\Phi$ e ogni componente di $A$) siano analitici in un tale $x_0 \in \Omega$\\
    Allora esiste ed è unica in un intorno $\U_{x_0} \subset \Omega$ una soluzione $u\in\mc{C}^2(\U_{x_0})$ tale che $u$ sia analitica in $x_0$.
\end{theorem}

\begin{definition}{Successioni maggiorate}{}
    Siano $F = \{f_i\}_I$ e $G = \{g_i\}_I$ due successioni di funzioni, con $f_i$ a valori in $\R$ e $g_i$ a valori in $\R$ non negativi.\\
    Diciamo che $F$ è \bemph{maggiorata} da $G$ se per ogni $i\in I$ vale $|f_i| \le g_i$, e scriviamo $F<<G$.
\end{definition}

\section{Ipersuperfici caratteristiche per PDE semlineari}

Discutiamo adesso l'estensione del teorema di \href{th:C-K}{C-K} in un dominio generale.

\begin{notation}
    Fino a contrordine, $\Omega \subset \R^n$ sarà un aperto connesso non vuoto, $\Sigma\subset\Omega$ sarà una $\mc{C}^k$-ipersuperficie regolare orientabile con normale $\nu$.
\end{notation}

Così possiamo applicare in coordinate di Riemann per ciascun $x_0 \in \Omega$ il teorema di C-K e considerare $\Omega = \R^n$ e $\Sigma = \R^{n-1}\embin\R^n$

Resta il problema di poter scrivere la PDE in forma normale, possibile nei casi in cui $\Sigma$ sia appropriatamente non degenere.

Consideriamo quindi il PDC per una PDE semilineare del secondo ordine:

\[A(x)\cdot H_u(x) + \Phi(x,u(x),\nabla u(x)) = 0 \quad u|_\Sigma = u_0 \quad \nu \cdot \nabla u|_\Sigma = u_1\]

Con molta allegria assumeremo sempre che tutti i dati siano disgustosamente analitici e ci limiteremo a studiare la possibilità di riscrittura in forma normale.

Consideriamo $x_0 \in \Sigma$ e le coordinate di Riemann $x = (t,\xi_2,...,\xi_n)$ in un intorno $\U_{x_0}$.

In particolare allora, un punto $x \in \U_{x_0}$ può essere parametrizzato come $x = x(t,\xi) = (t x_1 , \xi_2 x_2,...,\xi_n x_n )$, e se appartiene anche a $\Sigma$ abbiamo che $t=0$, dunque possiamo considerare la curva $t\mapsto x(t,\xi)$ che per costruzione identifica la retta normale a $\Sigma$ con origine in $x$, dunque il vettore $\nu(x)$ corrisponde alla derivata temporale di $x$ calcolata in $t=0$. Questo implica quindi che

\[\frac{\partial u}{\partial \nu} (x_0) = \nu \cdot \nabla u(x_0) = \frac{\de x}{\de t}(0,\xi_0) \cdot \nabla u(x_0) = \frac{\partial \tilde{u}}{\partial t}(0,\xi_0), \quad \text{dove} \quad \tilde{u}(t,\xi) = (u\circ x)(t,\xi)\]

Unendo queste considerazioni al lemma \href{lem:1.0.1}{1.0.1} possiamo riscrivere il nostro problema di Cauchy come:

\[\tilde{A}_{tt}(t,\xi) \frac{\partial^2 \tilde{u}}{\partial t^2}(t,\xi) + \tilde{A}_t(t,\xi)\cdot \frac{\partial \nabla_\xi \tilde{u}}{\partial t}(t,\xi) + \tilde{A}_\xi(t,\xi) \cdot H_{\tilde{u},\xi}(t,\xi) +  \tilde{\Phi}\left(t,\xi,\tilde{u}(t,\xi), \frac{\partial \tilde{u}}{\partial t}(t,\xi), \nabla_\xi \tilde{u}(t,\xi)\right) = 0\]

Con dati 

\[\tilde{u}(0,\xi) = \tilde{u}_0(\xi) \quad \frac{\partial \tilde{u}}{\partial t}(0,\xi) = \tilde{u}_1(\xi)\]

A questo punto una condizione sufficiente è che $\tilde{A}_{t,t}(t_0,\xi_0)\neq 0$, che per continuità implica che non lo sia in un intorno di $x_0$.

\begin{corollary}{C-K per PDE semilineari}{}
    Sia $x_0 = (0,\xi_0)\in\Sigma\subset \Omega$ tale che $\tilde{A}_{t,t}(0,\xi_0)\neq 0$ e assumiamo che negli intorni associati per gli argomenti dei dati questi siano analitici\\
    Allora in un intorno $U_{(0,\xi_0)}\subset\Omega$ esiste ed è unica la soluzione del PDC analitica in $\U_{x_0}$.
\end{corollary}

\begin{definition}{Ipersuperficie caratteristica}{}
    Siano $\Sigma \subset \Omega$ una $\mc{C}^k$-ipersuperficie regolare e sia $D$ un operatore differenziale semilineare del secondo ordine tali che per ogni $x_0 \in \Sigma$ esista $\U_{x_0}$ in cui $\Sigma$ sia luogo di zeri di una funzione $S$ tale che $\nabla S\neq 0$ e 
    \[A(x) \cdot \left(\frac{\partial S}{\partial x_j}(x) \frac{\partial S}{\partial x_k}(x)\right) = 0\]
    Allora $\Sigma$ si dice \bemph{ipersuperficie caratteristica} per $D$.
\end{definition}

Il problema di Cauchy associato a $D$ è detto \bemph{caratteristico} se i dati sono su una superficie caratteristica per $D$.

\chapter{PDE ellittiche}

\section{Problema di Dirichlet}

Concentriamoci sulle PDE ellittiche, in particolare l'equazione di Poisson $-\Delta u = f$, che con $f=0$ si riduce all'equazione di Laplace.

Considereremo questa equazione su $\Omega \subset \R^n$ e su $\R^n \setminus \bar{\Omega}$, dove $\Omega$ è un aperto con chiusura compatta, considereremo l'equazione come derivante dallo studio di soluzioni tempo-indipendenti dell'equazione del calore, dove $u$ rappresenta la temperatura in un continuo.

In quanto equazione ellittica, non ha superfici caratteristiche \Nick e dunque il PDC è mal posto! Dobbiamo formulare allora un problema diverso:

\begin{definition}{Problema di Dirichlet interno}{}
    Consiste nel trovare $u\in\mc{C}^0(\bar{\Omega})\cap\mc{C}^2(\Omega)$ tale che:
    \[-\Delta u = f \quad\text{su } \Omega, \qquad u|_{\partial\Omega} = u_0 \quad \text{su }\partial\Omega\] 
    Con $f \in \mc{C}^0(\Omega)$ e $u_0 \in \mc{C}^0(\partial\Omega)$ assegnate.
\end{definition}

\begin{definition}{Problema di Dirichlet esterno}{}
    Consiste nel trovare $u \in \mc{C}^0(\R^n \setminus \Omega)\cap\mc{C}^2(\R^n \setminus \bar{\Omega})$ tale che:
    \[-\Delta u = f \quad\text{su } \R^n \setminus \bar{\Omega}, \qquad u|_{\partial\Omega} = u_0 \quad \text{su }\partial\Omega, \qquad \lim_{R\to\infty} \max_{\partial B_R(0)} |u-u_\infty| = 0\]
    Con $u_\infty \in \R$ dato e $f \in \mc{C}^0(\R^n \setminus \bar{\Omega})$ e $u_0 \in \mc{C}^0(\partial\Omega)$ assegnate.
\end{definition}

A che ci interessano questi problemi? A poco in realtà, su domini generici, ma sappiamo che la soluzione esiste ed è unica; proviamo a studiarli con dati $f= 0$, $u_0 = 0$ e $u_\infty = 0$.

\begin{definition}{Funzioni armoniche}{}
    Sia $\Omega$ un aperto di $\R^n$ e sia $u\in\mc{C}^2(\Omega)$. Allora\begin{itemize}
        \item Se $-\Delta u \le 0$ allora $u$ si dice \bemph{subarmonica}
        \item Se $-\Delta u \ge 0$ allora $u$ si dice \bemph{superarmonica}
        \item Se $-\Delta u = 0$ allora $u$ si dice \bemph{armonica}
    \end{itemize}
\end{definition}

Le funzioni subarmoniche in particolare ci permettono di generalizzare il fatto che in un intervallo $[a,b]$ una funzione lineare o convessa ha massimo in $a$ o $b$.

\begin{theorem}{Principio del massimo}{}
    Sia $u\in\mc{C}^0(\bar{\Omega})\cap\mc{C}^2(\Omega)$. Valgono le seguenti:\begin{itemize}
        \item Se $u$ è subarmonica, \[\max_{\bar{\Omega}}u = \max_{\partial\Omega}u\] (analogamente per il minimo con le superarmoniche)
        \item Se $u$ è armonica, \[\max_{\bar{\Omega}} u = \max_{\partial\Omega}u, \quad \min_{\bar{\Omega}} u = \min_{\partial\Omega}u, \quad \max_{\bar{\Omega}}|u| = \max_{\partial\Omega}|u|\]
    \end{itemize}
\end{theorem}

\begin{proof}
    Banalmente, dato che $\partial\Omega\subset\bar{\Omega}$, abbiamo \[\max_{\partial\Omega} u \le \max_{\bar{\Omega}} u\]
    Assumiamo che $-\Delta u < 0$ e sia $x_0\in\bar{\Omega}$ punto di massimo per $u$ su $\bar{\Omega}$.\\
    Se $x_0\in\partial\Omega$, banale, quindi assumiamo che $x_0\in\Omega$\\
    Abbiamo in particolare che $\nabla u (x_0) = 0$ in quanto punto critico e che $H_u(x_0)$ è definita positiva, dunque in un intorno di $x_0$ il valore di $u$ è maggiore di $u(x_0)$, ma questa è una contraddizione, dunque abbiamo che $x_0\in\partial\Omega$.\\
    Ora assumiamo $-\Delta u \le 0$ e per $\varepsilon>0$ definiamo $u_\varepsilon(x) = u(x)+\varepsilon ||x||^2$, e abbiamo abbastanza evidentemente che $-\Delta u_\varepsilon < 0$, quindi:
    \[\max_{\bar{\Omega}}u \le \max{\bar{\Omega}} u_\varepsilon = \max_{\partial\Omega} u_\epsilon \le \max_{\partial\Omega} u + \varepsilon \max_{\partial\Omega}||x||^2 =: \max_{\partial\Omega} u + \varepsilon c \]
    Mandando $\varepsilon\to 0$ otteniamo la tesi.\\
    Nel caso in cui $-\Delta u = 0$ abbiamo che $\pm u$ sono subarmoniche e la tesi segue banalmente.
\end{proof}

\begin{remark}{}{}
    Abbiamo dimostrato anche che se una funzione è strettamente subarmonica, nei punti interni è strettamente più piccola del suo massimo sulla frontiera, inoltre il teorema vale per qualsiasi operatore della forma:
    \[Du(x) = A(x)\cdot H_u(x) + b(x)\cdot \nabla u(x)\]
    Dove $A(x)$ è definita positiva e $A(x),b(x)\in\mc{C}^0(\bar{\Omega})$
\end{remark}

\begin{theorem}{Unicità della soluzione del PDD interno}{}
    Siano $f\in\mc{C}^0(\Omega)$, $u_0\in \mc{C}^0(\partial\Omega)$ e $u\in\mc{C}^0(\bar{\Omega})\cap\mc{C}^2(\Omega)$ tali che $u$ sia soluzione del PDD interno con dati $f$ e $u_0$.\\
    Se $u$ esiste, è unica.
\end{theorem}
\begin{proof}
    Siano $u,u'$ due soluzioni con gli stessi dati iniziali. Abbiamo che $v = v-v'$ risolve il PDD interno con dati iniziali nulli. Dunque abbiamo che $\Delta v = 0$ e $v|_{\partial\Omega} = 0$, quindi è armonica e per il principio del massimo abbiamo
    \[\max_{\bar{\Omega}}|v| = \max_{\partial\Omega} |v| = 0 \Rarr v=0\Harr u=u' \]
\end{proof}

\begin{remark}{}{}
    Usando il principio del massimo, possiamo provare che l'esempio \href{exmp:4.0.1}{4.0.1} non ammette soluzione, in particolare perchè l'armonicità è una condizione abbastanza forte da rendere troppo stringenti le condizioni sulla derivata prima.\\
    Inoltre, il PDD interno con $f=0$ è ben posto! Abbiamo esistenza e unicità, ci manca solo la dipendenza continua dai dati.
\end{remark}
\begin{proof}
    Usiamo la norma $||\cdot||_\infty =: ||\cdot ||$ in $\mc{C}^0$ e siano $u,u'$ soluzioni con dati iniziali $u_0,u_0'$. Allora abbiamo che 
    \[||u-u'|| = \max_{\bar{\Omega}} |u-u'| = \max_{\partial\Omega} |u-u'| = ||u_0-u_0'||\]
\end{proof}

\begin{theorem}{Unicità delle soluzioni del PDD esterno}{}
    Siano $f\in\mc{C}^0(\R^n\setminus\bar{\Omega})$, $u_0\in \mc{C}^0(\partial\Omega)$, $u_\infty \in \R$ e $u\in\mc{C}^0(\R^n\setminus\Omega)\cap\mc{C}^2(\R^n\setminus\bar{\Omega})$ tali che $u$ sia soluzione del PDD esterno con dati $f$, $u_0$ e $u_\infty$.\\
    Se $u$ esiste, è unica.
\end{theorem}
\begin{proof}
    Siano $u,u'$ due soluzioni diverse con gli stessi dati, dunque consideriamo $v = u-u'$ che è soluzione del PDD esterno con dati nulli.\\
    In quanto $\bar{\Omega}$ è compatto, esiste $R>0$ tale che $\bar{\Omega}\subset B_R(0)$, dunque definiamo $\Omega_R := B_R(0) \setminus \bar{\Omega}$ che è un aperto con chiusura compatta $\bar{\Omega}_R = \bar{B}_R(0)\setminus\Omega$ e frontiera $\partial\Omega_R = \partial B_R(0) \cup \partial\Omega$.\\
    $v$ è armonica in $\R^n\setminus \bar{\Omega}$ dunque lo è anche in $\Omega_R$, quindi abbiamo
    \[|v|\le \max_{\bar{\Omega}_R}|v| = \max_{\partial B_R(0)} |v| \xrightarrow{R\to +\infty} 0  \Rarr v = 0 \Harr u=u'\]
\end{proof}

\section{Problemi di Neumann e Robin}

\begin{notation}
    Ricordiamoci che $\nabla f$ è il gradiente, ovvero il vettore delle derivate prime, $\nabla \cdot f$ è la divergenza, ovvero la somma delle derivate prime e $\nabla\cdot\nabla f = (\nabla \cdot\nabla) f = \Delta f$ è il laplaciano, ovvero la somma delle derivate seconde.
\end{notation}

\begin{theorem}{Teorema della divergenza di Gauss}{gauss}
    Sia $\Omega$ un aperto di $\R^n$ la cui frontiera è una $\mc{C}^k$-ipersuperficie regolare con normale $\nu$ e misura di Lebesgue indotta $S$ e sia $F:\bar{\Omega}\to\R^n$ un campo vettoriale $\mc{C}^1(\Omega)$ e $\mc{C}^0(\bar{\Omega})$. Allora vale
    \[\int\limits_\Omega \nabla \cdot F \de^n x = \oint\limits_{+\partial\Omega} F \cdot\nu \de S\]
\end{theorem}

\begin{remark}{}{}
    Nel caso $n=1$ con $\Omega =]a,b[$, si riduce al TFC.
\end{remark}

\begin{theorem}{Identità di Green}{green}
    Siano $u_1 \in \mc{C}^1(\bar{\Omega})$ e $u_2 \in \mc{C}^2(\bar{\Omega})$. Vale:
    \[\int\limits_{\Omega} u_1\Delta u_2 \de^n x = \oint\limits_{+\partial\Omega} u_1 \frac{\partial u_2}{\partial \nu}\de S - \int\limits_\Omega \nabla u_1 \cdot \nabla u_2 \de^n x \]
    Inoltre, se $u_1 \in \mc{C}^2(\bar{\Omega})$ vale:
    \[\int\limits_\Omega u_1\Delta u_2 - u_2 \Delta u_1 \de^n x = \oint\limits_{+\partial\Omega} u_1 \frac{\partial u_2}{\partial \nu} - u_2 \frac{\partial u_1}{\partial \nu} \de S\]
\end{theorem}

\begin{remark}{}{}
    Nel caso $n=1$ con $\Omega =]a,b[$, si riduce a:
    \[\int\limits_a^b u_1 u_2'' - u_2 u_1'' \de x = [u_1u_2' - u_2u_1']_a^b\]
\end{remark}

\begin{definition}{Problemi di Neumann e Robin}{}
    Trovare $u \in \mc{C}^2(\Omega)\cap\mc{C}^1(\bar{\Omega})$ tale che:
    \[-\Delta u = f \quad \text{su }\Omega, \qquad \frac{\partial u}{\partial\nu} + \alpha u = u_1 \quad\text{su }\partial\Omega\]
    Con $f \in \mc{C}^0(\Omega)$ e $u_1 \in \mc{C}^0(\partial\Omega)$ e $\alpha \ge 0$.\\
    Se $\alpha = 0$ si dice \bemph{problema di Neumann}, altrimenti \bemph{problema di Robin}.
\end{definition}

\begin{remark}{}{}
    In un PDN i dati non possono essere assegnati in modo indipendente:
    \[\int\limits_\Omega f\de^n x = \int\limits_\Omega -\Delta u \de^n x = \int\limits_\Omega -\nabla \cdot \nabla u \de^n x = \oint\limits_{+\partial \Omega} - \nabla u \cdot \nu \de S = -\int\limits_{\partial \Omega} u_1 \de S\]
\end{remark}

\begin{remark}{Interpretazione fisica del PDN e PDR per l'equazione del calore}{}
    Sia $u$ la temperatura di equilibrio in $\Omega$, allora abbiamo che  $q = -k\nabla u $ è il flusso di calore in $\Omega$ secondo la legge di Fourier, con $k>0$\footnote{se $k$ fosse negativo avremmo un flusso di calore dal freddo al caldo... esotico direi!}. Se nel PDD assegnavamo una temperatura al bordo, ora assegnamo un flusso di calore verso $\Omega$.\begin{itemize}
        \item Nel caso in cui $\alpha=0$, ovvero il PDN, avremmo \[u_1 = \frac{\partial u}{\partial \nu} = \nabla u \cdot \nu = \frac{-q\cdot \nu}{k}\] E in questo modo giustifichiamo anche la condizione \[\int\limits_\Omega f\de^n x =-\int\limits_{\partial \Omega} u_1 \de S\] Dato che $f$ deve modellare le sorgenti di calore interne a $\Omega$.
        \item Nel caso in cui $\alpha > 0$, ovvero il PDR, cerchiamo di modellare un caso in cui il flusso di calore può variare, entrante o uscente, in quanto non ho delle condizioni adeguate nè per il PDD nè per il PDN.
    \end{itemize}
\end{remark}

\begin{lemma}{Corollario del teorema di Lagrange}{lagrange}
    Sia $f\in\mc{C}^1(\Omega)$ tale che $\Omega$ sia connesso.\\
    Se $\nabla f = 0$, allora $f$ è costante su $\Omega$.
\end{lemma}

\begin{theorem}{}{}
    Sia $u \in \mc{C}^2(\Omega)\cap\mc{C}^1(\bar{\Omega})$ che risolva un PDN o PDR con dati $f$, $u_1$ e $\alpha$.\\
    Se $\alpha=0$, $u$ è unica a meno di costanti.\\
    Se $\alpha>0$, $u$ è unica.
\end{theorem}

\begin{proof}
    Siano $u,u'$ due soluzioni coi medesimi dati iniziali. Allora $v := u-u'$ risolve il problema con dati iniziali nulli, ovvero:\begin{itemize}
        \item Nel PDN:
        \[0 = \int\limits_\Omega v\Delta v \de^n x = \oint\limits_{+\partial\Omega} 0 v\de S - \int\limits_\Omega ||\nabla v||^2 \de^n x \Rarr \nabla v = 0\] Dunque $v$ è costante, ovvero le soluzioni $u$ e $u'$ sono al massimo differenti per una costante.
        \item Nel PDR:
        \[0 = \int\limits_\Omega v\Delta v \de^n x = -\alpha \oint\limits_{+\partial\Omega} v^2 \de S - \int\limits_\Omega ||\nabla v||^2 \de^n x\] Dunque abbiamo che $v$ è costante come sopra e che il suo quadrato ha integrale nullo, dunque $v=0$ e le soluzioni sono la stessa.
    \end{itemize}
\end{proof}

\begin{remark}{}{}
    Nel caso del PDN, pensiamo a un thermos, che non scambia calore con l'esterno. Tutte le distribuzioni uniformi di temperatura sono soluzioni al PDN con dati nulli, perchè senza flusso di calore da/verso l'esterno, all'equilibrio avremo una temperatura costante.\\
    E se $a<0$? In tal caso non avremmo l'unicità, basti pensare al problema in $n=2$ con $\Omega = B_1(0)$, $f$ nulla come $u_1$ e $\alpha = -1$, poichè avremmo come soluzioni ad esempio $u(x,y)=0$ e $u(x,y) = ax+by$ con $(a,b)\neq(0,0)$
\end{remark}

\section{La soluzione fondamentale}

Cerchiamo $u \in \mc{C}^2(\R^n)$ tale che $\Delta u = 0$ e $u(x) = \tilde{u}(z)$ con $z = ||x||^2$, ovvero soluzioni che presentino una simmetria radiale.

Abbiamo

\[\frac{\partial^2 u}{\partial x_i^2} = \frac{\partial}{\partial x_i} [2x_i\tilde{u}(z)] = 4x_i^2 \tilde{u}(z) + 2\tilde{u}'(z)\]

Sommando per ogni $i \in \{1,...,n\}$ e imponendo $\Delta u = 0$ otteniamo $4z\tilde{u}''(z) + 2n\tilde{u}'(z) = 0$ e possiamo risolvere quest'equazione! Dividiamoci in due casi:\begin{itemize}
\item Nel caso $n>2$
\begin{remark}{Consistenza dimensionale}{}
    Notiamo che se $z$ è una lunghezza, allora abbiamo che $\dim 2n\tilde{u}'(z) = [L]^{-1}\dim \tilde{u}$ e quindi $\dim 4z \tilde{u}''(z) = [L][L]^{-2}\dim\tilde{u} = [L]^{-1}\dim \tilde{u}$, dunque la nostra equazione è dimensionalmente consistente.
\end{remark}

Il fatto che sia dimensionalmente consistente ci suggerisce di scegliere $\tilde{u}(z) = z^\alpha$ con $\alpha \in \R$ da determinare. Abbiamo

\[4\alpha(\alpha-1)z^{\alpha-1} + 2n\alpha z^{\alpha - 1} = 0 \Rarr \alpha(2\alpha - 2 - n) = 0 \Rarr \alpha = 0 \quad \text{o}\quad \alpha = \frac{2-n}{2}\]

Il che ci porta a $\tilde{u}(z) = az^0 + b\sqrt{z}^{2-n}$ e dunque a $u(x) = a + b||x||^{2-n}$

\item Nel caso in cui $n=2$ invece ottengo $z\tilde{u}''(z) + \tilde{u}'(z) = [z\tilde{u}'(z)]'=0$ ovvero $z\tilde{u}'(z) = c$ e quindi $\tilde{u}(z) = c\log(x) + b$
\end{itemize}

Purtroppo non ottengo funzioni su tutto $\R^n$, ma proviamo a dedicarci solo a $\R^n\setminus\{0\}$.

\begin{definition}{Soluzione fondamentale dell'equazione di Laplace}{}
    Sia $n\ge 2$ e sia $G_n : \R^n\setminus\{0\}\to\R$ definita in questo modo:\begin{itemize}
        \item Se $n=2$ \[G_2(x) = \tilde{G}_2(||x||) \quad \text{dove} \quad \tilde{G}_2(z) = \frac{1}{4}\log(z)\]
        \item Se $n>2$ \[G_n(x) = \tilde{G}_n(||x||) \quad \text{dove} \quad \tilde{G}_n(z) =\frac{1}{(2-n)\omega_n} z^{2-n}\]
    \end{itemize}
    Dove $\omega_n$ è la misura di $\partial B_1(0)\subset \R^n$
\end{definition}

\begin{remark}{Ma perchè fondamentale?}{}
    Scegliamo $R>0$ e prendiamo $\Omega = B_R(0)$, dunque $\nu = R^-1 x$. Abbiamo che per ogni $n\ge 2$, si ha:
    \[\frac{\partial G_n}{\partial \nu} = \nabla G_n \cdot \nu = \frac{\partial \tilde{G}_n}{\partial R} =\frac{1}{R^{n-1}\omega_n}\]
    Ovvero il reciproco della misura di $\partial B_R(0)\subset \R^n$.
\end{remark}

\begin{definition}{Funzione localmente sommabile}{}
    Sia $f:\R^n \to \R$.\\
    $f$ si dice \bemph{localmente sommabile} se per ogni aperto $\Omega$ a chiusura compatta si ha che $f|_\Omega$ è sommabile.\\
    Scriveremo $f \in \Loc^1(\R^n)$.
\end{definition}

\begin{lemma}{}{}
    Sia $\Omega$ un aperto di $\R^n$ e sia $f:\Omega\to\R$ una funzione $\mc{C}^0(\Omega)$. Allora per ogni $x_0 \in \Omega$ vale:
    \[\lim_{\varepsilon\to 0} \frac{1}{|\partial B_\varepsilon (x_0)|}\oint\limits_{\partial B_\varepsilon(x_0)}f(x)\de S(x) = f(x_0)\]
\end{lemma}

\begin{lemma}{}{}
    Sia $f \in \mc{C}^2_c(\R^n)$ e sia $u:\R^n\to\R$ definita come
    \[u(x) := \int\limits_{\R^n} \frac{f(y)}{||x-y||^{n-2}}\de^n y\]
    Allora $u\in\mc{C}^2(\R^n)$ e vale
    \[\frac{\partial^2 u}{\partial x_j \partial x_k} = \int\limits_{\R^n} \frac{1}{||x-y||^{n-2}}\frac{\partial^2 f}{\partial x_j\partial x_k}(y)\de^n y\]
\end{lemma}

\begin{theorem}{}{}
    Sia $n\ge 2$ e sia $x_0 \in \R^n$. Valgono le seguenti:\begin{itemize}
        \item $G_n \in \mc{C}^\infty(\R^n \setminus \{0\})\cap \Loc^1(\R^n)$
        \item $\Delta G_n(x) = 0$ per qualsiasi $x \in \R^n \setminus \{0\}$
        \item Per una qualsiasi $f\in\mc{C}^2_c(\R^n)$ e per ogni $x \in \R^n$ vale:
        \[\int\limits_{\R^n}G_n(x-y)\Delta f(y) \de^n y = f(x)\]
        \item Per una qualsiasi $f\in\mc{C}^2_c(\R^n)$, la mappa $u:\R^n\to\R$ definita come
        \[u(x) = \int\limits_{\R^n} G_n(x-y)f(y)\de^n y\]
        è ben definita, $u\in \mc{C}^2(\R^n)$ e $\Delta u = f$. 
    \end{itemize}
\end{theorem}
\begin{proof}
    Consideriamo solo il caso $n>2$, il caso $n=2$ è analogo.\begin{itemize}
        \item Il fatto che sia $\mc{C}^\infty$ è automatico dalla definizione, è una composizione di mappe $\mc{C}^\infty$ sul dominio, mentre per dimostrare l'integrabilità locale basta integrare su una palla arbitraria:
        \[\int\limits_{B_{R_0}(0)} G_n(x)\de^n x = \int\limits_0^{R_0} \oint\limits_{\partial B_R(0)}\frac{R^{2-n}}{(n-n)\omega_n}\de\Omega_n R^{n-1}\de R = \frac{1}{n-2}\int\limits_0^{R_0} R\de R < +\infty\]
        \item Segue dalla costruzione.
        \item Prendiamo $f\in\mc{C}^2_c(\R^n)$ e innanzitutto notiamo che l'integrale (che chiameremo $I$) è effettivamente finito (in quanto il supporto di $f$ è contenuto in una qualche palla di centro $x$ e raggio $R$), dunque possiamo scrivere
        \[ \int\limits_{\R^n} G_n(x-y)\Delta f(y) \de^n y \le \int\limits_{B_R(x)}|G_n(x-y)|\cdot |\Delta f(y)|\de^n y \le \sup|\Delta f|\int\limits_{B_R(x)} |G_n(x-y)|\de^n y < +\infty  \]
        Ora dobbiamo solo dimostrare l'identità usando il corollario della convergenza dominata\footnote{Leggerete spesso queste parole.}
        \[\int\limits_{\R^n} G_n(x-y)\Delta f(y) \de^n y = \lim_{\varepsilon \to 0} \int\limits_{B_R(x)\setminus B_\varepsilon(x)}G_n(x-y)\Delta f(y) \de^n y = \lim_{\varepsilon\to 0} \int\limits_{B_R(x)} \chi_{B_\varepsilon(x)^c}G_n(x-y)f(y)\de^n y\]
        Dove in particolare
        \[|\chi_{B_\varepsilon(x)^c}G_n(x-y)\Delta f(y)|\le|G_n(x-y)\Delta f(y)| \in L^1(B_R(x))\]
        Dato che $G_n(x-y)$ è singolare se e solo se $x=y$, possiamo applicare Green
        \[I = \lim_{\varepsilon \to 0} \int\limits_{B_R(x)\setminus B_\varepsilon(x)}\Delta G_n(x-y) f(y) \de^n y + \lim_{\varepsilon\to 0} \oint\limits_{\partial [B_R(x)\setminus B_\varepsilon(x)]} G_n(x-y)\frac{\partial f}{\partial \nu}(y) - \frac{\partial G_n}{\partial \nu}(x-y) f(y)\de S(y)\]
        Ma dato che $\Delta G_n= 0$ diventa
        \[I=\lim_{\varepsilon\to 0}\oint\limits_{\partial B_\varepsilon(x)}\frac{\partial G_n}{\partial \nu}(x-y)f(y)\de S(y) - \lim_{\varepsilon\to 0}\oint\limits_{\partial B_\varepsilon(x)}\frac{\partial f}{\partial \nu}(y)G_n(x-y)\de S(y) =: A-B\]
        Studiamo $A$:
        \[\lim_{\varepsilon\to 0}\oint\limits_{\partial B_\varepsilon(x)}\frac{\partial G_n}{\partial \nu}(x-y)f(y)\de S(y) = \lim_{\varepsilon\to 0} \frac{1}{\partial B_\varepsilon(x)}\oint\limits_{\partial B_\varepsilon(x)}f(y)\de S(y) = f(x)\]
        Studiamo $B$:
        \[\left|\oint\limits_{\partial B_\varepsilon(x)}\frac{\partial f}{\partial \nu}(y)G_n(x-y)\de S(y)\right|\le \oint\limits_{\partial B_\varepsilon(x)}\left|\frac{\partial f}{\partial \nu}(y)\right||G_n(x-y)|\de S(y)\le |\tilde{G}_n(\varepsilon)|\oint\limits_{\partial B_\varepsilon(x)}\left|\frac{\partial f}{\partial \nu}(y)\right|\de S(y)\le\]
        \[\le \sup||\nabla f|| \tilde{G}_n(\varepsilon) \omega_n \varepsilon^{n-1} = c\varepsilon \to 0\]
        \item La buona definizione e doppia differenziabilità di $u$ seguono dal lemma di sopra, dobbiamo dimostrare $\Delta u = f$
        \[\Delta u(x) = \int\limits_{\R^n} G_n(z) \Delta f(x-z)\de^n z = \int\limits_{\R^n} G_n(x-y)\Delta f(y)\de S(y) = f(x)\]
    \end{itemize}
\end{proof}

\begin{remark}{}{}
    Il quarto punto funziona anche assumendo che $f$ sia semplicemente continua a supporto compatto, $u$ rimane ben definita ma bisogna dimostrare che sia $\mc{C}^2(\R^n)$ e che $\Delta u = f$.
\end{remark}
\begin{proof}
    Sia $g \in \mc{C}^2_c(\R^n)$ e assumiamo $u \in \mc{C}^2(\R^n)$. Consideriamo
    \[\int\limits_{\R^n}\Delta u (x) g(x) \de^n x = \int\limits_{\R^n}u(x)\Delta g(x)\de^n x = \int\limits_{\R^n}\int\limits_{\R^n}G_n(x-y)f(y)\Delta g(x)\de^n y\de^n x = \int\limits_{\R^n} f(x)g(x)\de^n x\]
    Che implica che per qualsiasi $g \in \mc{C}^2_c(\R^n)$ vale
    \[\int\limits_{\R^n}(\Delta u - f)(x)g(x)\de^n x = 0\]
    Ovvero $\Delta u = f$.
\end{proof}

\begin{theorem}{}{}
    Sia $n>2$ e consideriamo il PDD su $\R^n$ con dati $f \in \mc{C}^2_c(\R^n)$ e $u_\infty\in\R$:
    \[-\Delta u = f \quad \text{e}\quad \lim_{x\to\infty}|u(x)-u_\infty|\]
    Allora esiste ed è unica $u \in \mc{C}^2(\R^n)$ che in particolare è definita come:
    \[u(x):= u_\infty - \int\limits_{\R^n} G_n(x-y)f(y)\de^n y\]
    Inoltre esistono $R,C>0$ tali che 
    \[|u(x) - u_\infty| \le \frac{C}{||x||^{n-2}}||f||_1 \quad \text{e}\quad \supp(f) \subset B_R(0)\]
\end{theorem}
\begin{proof}
    L'unicità l'abbiamo dimostrata prima, l'esistenza segue dalla definizione con il teorema di prima, manca da dimostrare la limitatezza (l'esistenza di $R$ segue direttamente da Heine-Borel)\\
    Per ogni $R>0$ e $y \in B_R(0)$ vale $||x||\le ||x-y||+||y||\le ||x-y||+R$ e dunque $||x-y||\ge ||x|| - R$
    TODO
\end{proof}

\section{Formula della media}

La formula della media è importantissima per lo studio di molte notevoli proprietà delle funzioni armoniche. In particolare vedremo la forma forte del principio del massimo.

\begin{theorem}{Formula di rappresentazione}{}
    Sia $\Omega$ un aperto di $\R^n$ con chiusura compatta e frontiera $\mc{C}^1$-regolare orientabile e sia $u \in \mc{C}^2(\Omega)\cap\mc{C}^0(\bar{\Omega})$ tale che $\Delta u \in L^\infty$. Allora per ogni $x \in \Omega$ vale:
    \[u(x) = \oint\limits_{\partial\Omega} \frac{\partial G_n}{\partial \nu}(x-y) u(y) - G_n(x-y)\frac{\partial u}{\partial \nu}(y) \de S(y) + \int\limits_\Omega G_n(x-y)\Delta u(y)\de^n y\]
\end{theorem}
\begin{proof}
    Per ogni $x\in\Omega$ abbiamo
    \[\int\limits_\Omega G_n(x-y)\Delta u(y)\de^n y = \lim_{\varepsilon\to 0} \int\limits_{\Omega\setminus B_\varepsilon(x)} G_n(x-y)\Delta u(y)\de^n y =\]
    \[= \lim_{\varepsilon\to 0} \int\limits_{\Omega\setminus B_\varepsilon(x)}\Delta G_n(x-y) u(y)\de^n y + \lim_{\varepsilon\to 0}\oint\limits_{\partial[\Omega\setminus B_\varepsilon(x)]} G_n(x-y)\frac{\partial u}{\partial \nu}(y) - \frac{\partial G_n}{\partial \nu}(x-y) u(y) \de S(y) = \]
    \[= \oint\limits_{\partial\Omega} G_n(x-y)\frac{\partial u}{\partial \nu}(y) - \frac{\partial G_n}{\partial \nu}(x-y) u(y) \de S(y) - \lim_{\varepsilon\to 0}\oint\limits_{\partial B_\varepsilon(x)} G_n(x-y)\frac{\partial u}{\partial \nu}(y) - \frac{\partial G_n}{\partial \nu}(x-y) u(y) \de S(y) = \]
    \[= \oint\limits_{\partial\Omega} G_n(x-y)\frac{\partial u}{\partial \nu}(y) - \frac{\partial G_n}{\partial \nu}(x-y) u(y) \de S(y) + u(x) = \int\limits_\Omega G_n(x-y)\Delta u(y)\de^n y\]
\end{proof}

Adesso abbiamo uno strumento potensissimo da applicare alle funzioni armoniche, infatti

\begin{corollary}{Formula di rappresentazione per le funzioni armoniche}{}
    Sia $\Omega$ un aperto di $\R^n$ con chiusura compatta e frontiera $\mc{C}^1$-regolare orientabile e sia $u \in \mc{C}^2(\Omega)\cap\mc{C}^0(\bar{\Omega})$ tale che $\Delta u = 0$. Allora per ogni $x \in \Omega$ vale:
    \[u(x) = \oint\limits_{\partial\Omega} \frac{\partial G_n}{\partial \nu}(x-y) u(y) - G_n(x-y)\frac{\partial u}{\partial \nu}(y) \de S(y)\]
\end{corollary}

\begin{theorem}{}{}
    Sia $\Omega$ un aperto e $u:\Omega \to \R$ armonica. Allora $u$ è anche liscia
\end{theorem}
\begin{proof}
    Dobbiamo dimostrare che per tutti gli $x\in\Omega$ esistono tutte le derivate miste.\\
    Fissiamo $x_0 \in \Omega $ e $\varepsilon>0$ tale che $B_\varepsilon(x_0)\subset\Omega$. Per ogni $x \in B_\varepsilon(x_0)$ abbiamo:
    \[u(x) = \oint\limits_{\partial B_\varepsilon(x_0)} \frac{\partial G_n}{\partial \nu}(x-y) u(y) - G_n(x-y)\frac{\partial u}{\partial \nu}(y) \de S(y)\]
    Sia $0<\varepsilon' < \varepsilon$. Dimostriamo che $u$ è liscia in $B_{\varepsilon'}(x_0)$.
    Sia $\alpha \in \Z_+^n$ e sia $\partial^\alpha u$ la derivata mista di $u$ per gli indici di $\alpha$. Dato che per ogni $x \in B_{\varepsilon'}(x_0)$ e $y \in \partial B_\varepsilon(x_0)$ la funzione $G_n(x-y)$ è liscia, 
    TODO
\end{proof}

\begin{theorem}{Formula della media}{mean}
    Sia $u \in \mc{C}^2(\Omega)$ tale che $\Delta u = 0$. Allora per ogni $x \in \Omega$ e $R>0$ tale che $\bar{B}_R(x)\subset \Omega$ vale:
    \[u(x) = \frac{1}{|\partial B_R(x)|}\oint\limits_{\partial B_R(x)}u(y) \de S(y) = \frac{1}{| B_R(x)|}\int\limits_{B_R(x)}u(y)\de^n y\] 
\end{theorem}
\begin{proof}
    Per la formula di rappresentazione ho
    \[u(x) = \oint\limits_{\partial\Omega} \frac{\partial G_n}{\partial \nu}(x-y) u(y) - G_n(x-y)\frac{\partial u}{\partial \nu}(y) \de S(y) =\]
    \[= \frac{1}{|\partial B_R(x)|}\oint\limits_{\partial B_R(x)}u(y) \de S(y) - \tilde{G}_n(R) \oint\limits_{\partial B_R(x)} \frac{\partial u}{\partial \nu}(y) \de S(y) =\]\[= \frac{1}{|\partial B_R(x)|}\oint\limits_{\partial B_R(x)}u(y) \de S(y) - \int\limits_{B_R(x)} \Delta u (y)\de^n y = \frac{1}{|\partial B_R(x)|}\oint\limits_{\partial B_R(x)}u(y) \de S(y) - 0\]
    Per dimostrare la seconda uguaglianza basta usare il TFA
\end{proof}
\begin{remark}{}{}
    Se vale la formula della media e $u$ è continua, allora $u$ è armonica.
\end{remark}

\begin{theorem}{Principio del massimo forte}{}
    Sia $\Omega$ un aperto di $\R^n$ connesso con chiusura compatta e sia $u \in \mc{C}^0(\bar{\Omega})$ tale che per ogni $x\in\Omega$ e $R>0$ tali che $\bar{B}_R(x)\subset \Omega$ valga la formula della media. Allora se $u$ assume massimo, minimo o massimo assoluto in un punto di $\Omega$, è costante su $\Omega$.
\end{theorem}
\begin{proof}
    Assumiamo che $x_0 \in \Omega$ sia punto di massimo per $u$, gli altri casi seguiranno analogamente. Definiamo $U\subset \Omega$ come l'insieme dei punti di massimo globale di $u$, che chiaramente non è vuoto in quanto $x_0\in U$.\\
    Abbiamo che $U = u^{-1}(\{u(x_0)\})$ dunque è chiuso.\\
    Vogliamo dimostrare che $U$ è aperto. Sia $x\in U$ e supponiamo per assurdo che esista una successione $\{x_i\}_\N$ tale che per ogni $i \in \N$ esista $x_i \in B_{2^{-i}}(x)$ tale che $x_i\notin U$. Per la formula della media avremmo:
    \[u(x) = \frac{1}{|B_|}\]
    TODO
\end{proof}

\begin{remark}{}{}
    Chiaramente la forma forte implica la forma debole.
\end{remark}

\begin{theorem}{Teorema di Liouville}{}
    Sia $u:\R^n\to\R$ armonica su $\R^n$. Se $u$ è limitata superiormente o inferiormente, allora è costante.
\end{theorem}
\begin{proof}
    Assumiamo che $u$ sia limitata inferiormente. Definiamo $v := u-\inf u \ge 0$. Allora $v$ è armonica, dunque è liscia. In particolare su ogni direzione $x_k$ vale:
    \[\Delta \frac{\partial v}{\partial x_k} =\sum_{i = 1}^n \frac{\partial^3 u}{\partial x_i^2 \partial x_k} = \frac{\partial \Delta v}{\partial k} = 0\]
    Ovvero, le derivate prime di una funzione armonica sono armoniche, dunque possiamo applicare alle derivate di $v$ la formula della media
    \[\left|\frac{\partial v}{\partial x_k}(x)\right| =\frac{1}{|B_R(x)|}\left| \int\limits_{B_R(x)}\frac{\partial v}{\partial y_k}(y) \de^n y\right|\]
    Ora, sia $F : \R^n\to\R^n$ definito come $F_k(x) = v(x)e_k$, dunque la sua divergenza è la somma delle derivate di $v$, quindi posso applicare Gauss:
    \[\left|\frac{\partial v}{\partial x_k}(x)\right| = \frac{1}{|B_R(x)|} \oint\limits_{\partial B_R(x)}|v(y) \nu_k |\de S(y) = \frac{1}{|B_R(x)|} \oint\limits_{\partial B_R(x)}|v(y)|\de S(y) = \frac{1}{|B_R(x)|} v(x) |\partial B_R(x)| = \frac{n}{R}v(x)\]
    Dunque mandando $R\to +\infty$ otteniamo che la derivata è nulla in ogni direzione su tutto $\R^n$, dunque $v$ (come automaticamente $u$) è costante.\\
    Se $u$ è limitata superiormente, la dimostrazione è analoga.
\end{proof}

Abbiamo che questo teorema vale per le funzioni armoniche in $L^\infty(\R^n)$, ma vale anche negli altri $L^p(\R^n)$? In effetti sì, e in modo ancora più forte, ma prima ricordiamoci di un certo risultato

\begin{lemma}{Disuguaglianza di Holder}{holder}
    Sia $(X,\mu)$ uno spazio con misura, siano $p,q \in [1,+\infty]$ tali che $p^{-1}+q^{-1}= 1$ e siano $f\in L^p(X,\mu)$ e $g \in L^q(X,\mu)$. Allora vale:
    \[f g \in L^1(X,\mu) \quad \text{e}\quad ||fg||_1 \le ||f||_p||g||_q\]
\end{lemma}

\begin{theorem}{}{}
    Sia $p \in [1,+\infty[$ e sia $u:\R^n\to\R$ armonica e $p$-sommabile.\\
    Allora $u$ è la funzione identicamente nulla.
\end{theorem}
\begin{proof}
    Sia $x \in \R^n$ e $R>0$. Per la formula della media vale:
    \[|u(x)| = \frac{1}{|B_R(x)|}\left| \int\limits_{B_R(x)} u(y)\de^n y\right| \le \frac{1}{|B_R(x)|}\int\limits_{B_R(x)} |u(y)|\de^n y = \frac{1}{|B_R(x)|} ||u \chi_{B_R(x)}||_1\]
    Applicando \href{lemma:holder}{Holder} con $p' = p(p-1)^{-1}$ vale:
    \[|u(x)|\le \frac{1}{|B_R(x)|} ||u||_p ||\chi_{B_R(x)}||_{p'} = \frac{||u||_p}{|B_R(x)|^{1/p}} \to 0\]
    Dunque $u(x) = 0$
\end{proof}

\section{Funzioni armoniche su domini illimitati}

Sia $\Omega \in \R^n$ un aperto con chiusura compatta e superficie $1$-regolare orientabile con normale $\nu$.

\begin{definition}{PDN esterno}{}
    Trovare $u\in \mc{C}^2(\R^n\setminus \bar{\Omega})\cap \mc{C}^0(\R^n\setminus\Omega)$ tale che:
    \[-\Delta u = f \quad \text{su }\R^n\setminus\bar{\Omega}, \qquad \frac{\partial u}{\partial \nu} = u_1 \quad \text{su }\partial\Omega, \qquad \lim_{x\to+\infty} |u(x)-u_\infty| = 0 \]
    Con $f \in \mc{C}^0(\R^n\setminus\bar{\Omega})$, $u_1 \in \mc{C}^0(\partial\Omega)$ e $u_\infty\in\R$ assegnati. 
\end{definition}

L'idea per studiare l'unicità delle soluzioni a questo genere di problemi è chiudere $\Omega$ in una palla $B_N(0)$ e definendo $\Omega_N := B_N(0) \setminus \bar{\Omega }$, trattarli come PDN interni per ciascuna palla e poi mandarla all'infinito, perchè infatti avremmo (definendo $v = u-u'$ come nelle solite dimostrazioni):

\[\int\limits_{\Omega_N} v\Delta v \de^n x = -\int\limits_{\Omega_N}||\nabla v||\de^n x + \oint\limits_{\partial \Omega} v \frac{\partial v}{\partial \nu}\de S + \oint\limits_{\partial B_N(0)} v \frac{\partial v}{\partial \nu}\de S\]

Sappiamo che in quanto $v$ è soluzione con dati nulli, $\Delta v=0$ come la sua derivata normale sul bordo di $\Omega$, però non è detto che lo sia sul bordo della palla: questo ci richiede che all'infinito, $v\sim ||x||^{-k}$.

Vedremo che le funzioni armoniche soddisfano questa cosa (in $n>2$ attenti!!!) perchè dai porca miseria, credevate davvero che ci sia qualche bella proprietà che le funzioni armoniche non hanno?

\begin{corollary}{Corollario del principio del massimo in forma forte}{}
    Siano $u,u' \in \mc{C}^2(\Omega) \cap \mc{C}^0(\bar{\Omega})$ due soluzioni del PDD con $f$ nulla e $u_0,u_0' \in \mc{C}^0(\partial\Omega)$ tali che $u_0\ge u_0'$ ed esista un punto $x_0 \in \partial\Omega$ dove $u_0(x_0)>u_0'(x_0)$.\\
    Allora $u>u'$ su tutto $\Omega$
\end{corollary}
\begin{proof}
    Sia $v:= u-u'$, che è soluzione del PDD $\Delta v = 0$ e $v_0 := u_0-u_0'\ge 0$. Abbiamo che in almeno in un punto $x_0 \in \partial \Omega$, $v_0(x_0) >0$.\\
    Sia $x \in \Omega$. Ho due casi: o $v(x)$ è maggiore del minimo di $v$ su $\partial \Omega$, dunque $v(x)$ è maggiore di $0$, o è uguale al minimo di $v$ su $\partial \Omega$, ma in quel caso $v$ dovrebbe essere costante e maggiore di $0$ in quanto lo è in almeno un punto, dunque $u>u'$ su tutto $\Omega$.
\end{proof}

Ci serve una roba del genere ma su domini illimitati.

\begin{proposition}{}{}
    Sia $u$ armonica su $\R^n \setminus \bar{\Omega}$ e continua su $\R^n \setminus \Omega$ tale che $u|_{\partial\Omega}\ge 0$ e $u\to 0$ all'infinito.\\
    Allora, $u\ge 0$ su $\R^n \setminus \Omega$.
\end{proposition}
\begin{proof}
    Per definizione:
    \[\lim_{x\to\infty} u(x) = 0 \Rarr \lim_{R\to+\infty}\sup_{B_R(0)}|u| = 0 \Rarr \forall \varepsilon >0, \exists R_\varepsilon > 0 : \forall R>R_\varepsilon, \sup_{B_R(0)}|u| < \varepsilon\wedge \Omega \subset B_R(0)\]
    Osserviamo dunque che $u$ ristretta a $B_R(0)$ è strettamente maggiore di $-\varepsilon$. Sia $u' := -\varepsilon$.\\
    Notiamo che soddisfa il PDD interno a $\Omega_R := B_R(0)\setminus \bar{\Omega}$ con $f$ nulla e condizione di bordo $-\varepsilon$, e $u|_{\partial \Omega_R}>-\varepsilon$ per il corollario di prima, dunque $u(x)>-\varepsilon$ su tutto $\Omega_R$ per ogni $R>R_\varepsilon$.\\
    Mandando $\varepsilon\to 0$ otteniamo $u\ge 0$ su tutto $\R^n \setminus \Omega$.
\end{proof}

\begin{theorem}{}{}
    Sia $n\ge 3$ e $u$ armonica su $\R^n\setminus \bar{\Omega}$ tale che $u\to 0$ quando $x\to\infty$.\\
    Allora esistono $C,R>0$ tali che $\bar{\Omega}\subset B_R(0)$ e in $\R^n\setminus B_R(0)$:
    \[|u| \le \frac{C}{||x||^{n-2}}\qquad \text{e}\qquad \left|\frac{\partial u}{\partial x_k}\right|\le \frac{\tilde{C}}{||x||^{n-1}} \quad \forall k\]
\end{theorem}
\begin{proof}
    Per definizione di limite abbiamo:
    \[\exists R>0 \quad \text{t.c.} \quad \bar{\Omega}\subset B_R(0) \quad \text{e} \quad |u| <\frac{1}{(n-2)\omega_n} \quad \text{su } \partial B_R(0)\]
    Consideriamo $v:= u + R^{n-2}G_n = u(x) - \frac{R^{n-2}}{(n-2)\omega_n ||x||^{n-2}}$ e osserviamo che $v$ risolve il seguente PDD esterno:
    \[\Delta v = 0 \quad\text{su }\R^n \setminus\bar{B}_R(0), \qquad \lim_{x\to\infty}v(x) = 0, \qquad v|_{\partial B_R(0)} = u|_{\partial B_R(0)} - \frac{1}{(n-2)\omega_n} < 0\]
    Dunque per la proposizione precedente, $v \le 0$ su tutto $\R^n \setminus\bar{B}_R(0)$, dunque $u(x) \le \frac{R^{n-2}}{(n-2)\omega_n ||x||^{n-2}}$
    Poi procediamo analogamente con $v' = u - R^{n-2}G_n$.\\
    Adesso consideriamo $R$ tale che $|u(x)| \le c||x||^{2-n}$
    TODO
\end{proof}

\begin{theorem}{Unicità della soluzione dei PDN}{}
    Siano $u,u'$ due soluzioni al PDN:
    \[\Delta u = f \quad \text{su }\R^n\setminus \bar{\Omega},\qquad \frac{\partial u}{\partial \nu} = u_1 \quad \text{su }\partial\Omega, \qquad \lim_{x\to\infty}u(x) = u_\infty\]
    Con gli stessi dati. Allora $u=u'$
\end{theorem}
\begin{proof}
    Definiamo $v = u-u'$ che risolve il PDN esterno con dati nulli. Sia dunque $R>0$ tale che $\bar{\Omega}\subset B_R(0)$ e $|v|\le C||x||^{2-n}$ e $||\nabla v||\le C||x||^{1-n}$, allora posto $\Omega_N := B_R(0)\setminus \bar{\Omega}$ si ha:
    \[\int\limits_{\Omega_R} v\Delta v \de^n x = 0 = \oint\limits_{\partial \Omega_R} v \frac{\partial v}{\partial \nu}\de S - \int\limits_{\Omega_R} ||\nabla v||^2 \de^n x = \oint\limits_{\partial B_R(0)} v \frac{\partial v}{\partial \nu}\de S - \int\limits_{\Omega_R} ||\nabla v||^2 \de^n x\]
    Vediamo che quando $R\to \infty$, il secondo termine tende all'integrale su tutto il dominio di $||v||^2$, mentre il primo termine può essere maggiorato in questo modo:
    \[\left|\oint\limits_{\partial B_R(0)} v \frac{\partial v}{\partial \nu}\de S\right|\le \oint\limits_{\partial B_R(0)} \frac{C}{||x||^{n-2}} \frac{C}{||x||^{n-1}}\de S = \frac{C^2\omega_n}{R^{n-2}}\to 0\]
    Quindi all'infinito abbiamo
    \[0 = \lim_{R\to +\infty} -\int\limits_{\Omega_R} ||\nabla v||^2 \de^n x = 0 \Rarr \nabla v = 0 \Rarr v = 0 \Rarr u = u'\]
\end{proof}

\chapter{PDE iperboliche}

In questo capitolo considereremo l'equazione di Klein-Gordon con $\mu > 0$, che con $\mu = 0$ a volte ridurremmo all'equazione delle onde:
\[\frac{1}{c^2}\frac{\partial^2 u}{\partial t^2} - \Delta_x u + \mu^2 u = 0\]
Con $u: \R^{n+1}\to \R$, dove consideriamo i punti come $(t,x)$ con $t \in \R$ e $x \in\R^n$.
Il simbolo principale di questo operatore è la matrice identità con il primo elemento invertito di segno, dunque è una PDE iperbolica; inoltre la superficie $\Sigma := \{(0,x)\in \R^{n+1}\}$ non è caratteristica \Nick e quindi possiamo dare condizioni su di essa senza che C-K esploda.

Scopriremo che il parametro $c^2$ rappresenta una velocità di propagazione finita, cosa effettivamente importante dal punto di vista fisico.

\section{Unicità su domini limitati}

\begin{definition}{Problema di Cauchy con condizioni al bordo}{}
    Sia $\Omega \subset \R^n$ un aperto con chiusura compatta e frontiera regolare orientabile.\\
    Fissiamo $T>0$ e definiamo $\Omega_T :=\Omega\times ]-T,T[$ e indichiamo con abuso di notazione $\bar{\Omega}_T:=\bar{\Omega}\times ]-T,T[$.\\
    Il \bemph{problema di Cauchy con condizioni al bordo} per l'equazione di K-G consiste nel trovare una $u\in \mc{C}^2(\Omega_T)$ tale che:
    \[T_1 : \frac{1}{c^2}\frac{\partial^2 u}{\partial t^2} - \Delta_x u + \mu^2 u = f \quad \text{su }\Omega_T\]
    \[T_2 : u(x,0) = u_0(x) \quad \text{su }\bar{\Omega}\]
    \[T_3 : \frac{\partial u}{\partial t}(x,0) = u_1(x)\quad \text{su }\bar{\Omega}\]
    \[T_4 : \sin\theta \frac{\partial u}{\partial \nu} + \cos\theta u = u_{BC} \quad \text{su } \partial\Omega \times ]-T,T[\]
    Con $c,\mu \in \R$, $\theta \in [0,2\pi]$, $f \in \mc{C}^0(\bar{\Omega}_T)$, $u_0 \in \mc{C}^2(\bar{\Omega})$, $u_1 \in \mc{C}^1(\bar{\Omega})$ e $u_{BC} \in \mc{C}^1(\partial\Omega \times ]-T,T[)$\footnote{Prendendo $\theta = 0$ possiamo anche imporre $\mc{C}^2$} dati.
\end{definition}
\begin{remark}{Interpretazioni fisiche e compatibilità tra i dati}{}
    $T_1$ ci dice cosa succede alla membrana quando sollecitiamo il tamburo, con la $f$ che rappresenta le nostre sollecitazioni.\\
    $T_2$ e $T_3$ ci danno le condizioni della membrana in un certo istante $t=0$; se nessuno ha battuto la membrana, $u_0$ sarà costante e $u_1$ nulla.\\
    $T_4$ ci dice che la membrana del tamburo sul bordo del tamburo è sempre ferma; il tamburo corrisponde a $u_{BC} = 0$ e $\theta = 0$, ovvero che la membrana sia vincolata a stare ferma su un piano.\\
    Inoltre il paramentro $\theta$ ci permette di considerare tutti i problemi visti sopra: $\theta = 0 \Rarr$ Dirichlet nelle situazioni tempo-indipendenti ellittiche, $\theta = \pi/2\Rarr$ Neumann e $\theta in ]0,\pi/2[\Rarr$ Robin in quanto non si annulla nulla e entrambi i fattori sono positivi; in poche parole, con una condizione al bordo prendiamo tutti i casi ellittici.\\
    Inoltre abbiamo una certa dipendenza tra i dati, infatti:
    \[\sin\theta \frac{\partial u}{\partial \nu}(x,0) + \cos\theta u(x,0) = u_{BC}(x,0)\Rarr u_{BC}(x,0) = \sin\theta \frac{\partial u_0}{\partial \nu}(x) + \cos\theta u_0(x)\]
    E analogamente
    \[\sin\theta\frac{\partial}{\partial t} \frac{\partial u}{\partial \nu}(x,0) + \cos\theta\frac{\partial}{\partial t} u(x,0) =\frac{\partial}{\partial t} u_{BC}(x,0) \Rarr \frac{\partial}{\partial t} u_{BC}(x,0) =  \sin\theta \frac{\partial u_1}{\partial \nu}(x) + \cos\theta u_1(x)\]
    Che sono condizioni necessarie sui dati per l'esistenza di soluzioni.\\
    Infine, dobbiamo considerare il fatto che noi stiamo trattando il tempo in maniera simmetrica: conoscendo lo stato della membrana in un $t=0$, vogliamo ricostruirne le condizioni sia prima che dopo.\\
    L'equazione delle onde infatti presenta quella che si dice \bemph{time-reversal simmetry}, ovvero se $u(x,t)$ è soluzione, lo è anche $u(x,-t)$. Purtroppo altre equazioni, come quella del calore, non ci fanno questo stesso regalo.
\end{remark}

\begin{theorem}{Unicità delle soluzioni del PDC-BC}{}
    Siano $u,u'$ due soluzioni del PDC-BC con gli stessi dati $c$, $\mu$, $\theta$, $f$, $u_0$, $u_1$ e $u_{BC}$.\\
    Allora $u=u'$
\end{theorem}
\begin{proof}
    Sia $v = u-u'$. Questa risolve il PDC-BC con dati $c$, $\mu$, $\theta$ e gli altri dati nulli. Definiamo la \bemph{densità di energia} $E_v$ come:
    \[E_v = \frac{1}{2}\left[ \frac{1}{c^2}\left(\frac{\partial v}{\partial t}\right)^2 + ||\nabla_x v||^2 + \mu^2 v^2 \right] \in \mc{C}^1(\bar{\Omega}_T)\]
    Abbiamo che $E_v(x,t)\ge 0$, $E_v(x,0) = 0$ ed è costantemente zero se e solo se $v$ è costantemente 0. Dato che è $\mc{C}^1$ posso derivarla nel tempo facendo orribili contacci ottenendo:
    \[\frac{\partial E_v}{\partial t} = \nabla_x \cdot \frac{\partial v}{\partial t} \nabla_x v\]
    Dunque possiamo definire la funzione
    \[E_{v,\Omega}(t) := \int\limits_{\Omega} E_v(x,t)\de^n x\]
    Che è $\mc{C}^1$ su $]-T,T[$ e si annulla in $t=0$
    \[\frac{d}{d t}E_{v,\Omega}(t) = \int\limits_{\Omega} \frac{\partial E_v}{\partial t}(x,t)\de^n x = \int\limits_{\Omega}\nabla_x \cdot \frac{\partial v}{\partial t}(x,t) \nabla_x v(x,t)\de^n x = \oint\limits_{\partial\Omega}\frac{\partial v}{\partial \nu} \frac{\partial v}{\partial t}\de S\]
    Consideriamo dunque due casi:\\
    Se $\theta = 0, \pi/2$ allora su $\partial\Omega \times ]-T,T[$ abbiamo
    \[v = 0 \quad \text{o} \quad \frac{\partial v}{\partial t} = 0\Rarr \frac{d}{d t}E_{v,\Omega}(t) =0 \wedge E_{v,\Omega}(0) \Rarr E_v = 0 \Rarr v = 0\]
    TODO caso $0<\theta < \pi/2$
\end{proof}
\begin{remark}{}{}
    Abbiamo chiamato $E_v$ "densità di energia", e dunque $E_{v,\Omega}$ corrisponderebbe all'energia della funzione $v$ sulla regione $\Omega$. Abbiamo anche
    \[\frac{d}{d t}E_{v,\Omega}(t) = \int\limits_{\Omega}\nabla_x \cdot J \de^n x = \oint\limits_{\partial \Omega}J \cdot \nu \de S\]
    Dove $J$ è il nostro \bemph{flusso di energia}. 
\end{remark}

\section{Velocità di propagazione finita}

Una proprietà interessante dell'equazione di K-G (e delle onde) è che le soluzioni propagano il loro supporto a velocità finita, in particolare una soluzione a supporto compatto lo rimane per tutti gli istanti successivi.

Per dimostrare questa cosa, ci servirà il prossimo lemma.

\begin{lemma}{}{}
    Sia $I = [0,1]$ e sia $F \in \mc{C}^0(I^2)$. Definiamo
    \[f(t) = \int\limits_0^t F(s,t)\de s\]
    Allora abbiamo che 
    \[\frac{\partial F}{\partial t}\in \mc{C}^0(I^2)\Rarr f \in \mc{C}^1(I) \quad \text{e}\quad \frac{d}{dt}f(t) = F(t,t) + \int\limits_0^t \frac{\partial F}{\partial t}(s,t)\de s\]
\end{lemma}
\begin{proof}
    TODO
\end{proof}

Ci servono un paio di risultatelli tecnici

\begin{definition}{Cono di dipendenza}{}
    Sia $(x_0,t_0)\in \R^{n+1}$. Il \bemph{cono di dipendenza} con vertice in $(x_0,t_0)$ è l'insieme $D_{x_0,t_0} := \{(x,t) \in \R^{n+1}: t\le t_0, ||x-x_0||\le c |t-t_0|\}$.\\
    TODO immagine del cono
\end{definition}

Vogliamo dimostrare che il valore di $u(x_0,t_0)$ dipende soltanto dai valori di $u$ in $D_{x_0,t_0}$, varrebbe anche su domini limitati ma noi lo facciamo su tutto $\R^{n+1}$

\begin{theorem}{}{}
    Sia $u \in \mc{C}^2(\R^{n+1})$ che risolva l'equazione di K-G. Supponiamo anche che $u(x,0) = 0$ e $\frac{\partial u}{\partial t} (x,0) = 0$ in $B_{ct_0}(x_0)$ per un certo $(x_0,t_0)$.\\
    Allora $u=0$ su $D_{x_0,t_0}\cap \R^n\times [0,t_0]$.
\end{theorem}
\begin{proof}
    Consideriamo la funzione $e_u : [0,t_0]\to \R$ definita come:
    \[e_v(t):= \int\limits_{B_{c(t_0-t)}(x_0)}E_u(x,t)\de^n x = \int\limits_0^{c(t_0-t)} \oint\limits\limits_{\partial B_R(x_0)} E_u(x,t)\de S(x)\de R =: \int\limits_0^{c(t_0-t)} F(R,t)\de R \]
    Per il corollario della convergenza dominata, $F \in \mc{C}^0([0,t_0]^2)$ come la sua derivata temporale, dunque il suo limite per $R\to 0$ è $0$
    TODO
\end{proof}


\end{document}